{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6>**Classical Statistics: MLE and Hypothesis Testing**</font>\n",
    "\n",
    "\n",
    "## Why test hypotheses and estimate parameters?\n",
    "\n",
    "**Observations** are measurements of the properties of natural objects, and may provide insights for new theories.\n",
    "\n",
    "**Theories** are **potential** models describing how things work. **Good theories** come with predictions on the observed properties of unseen objects.\n",
    "\n",
    "To learn something new about the Universe we need to find ways to answer to questions such as:\n",
    "- does our new theory agree with the data (Hypothesis testing), or\n",
    "- what are the parameters of an existing theory (Inference on Parameters), or\n",
    "- which theory is more probable (Model Comparison; we'll see that in a following session)\n",
    "\n",
    "# 1. Constraining the parameter of a theory: Maximum Likelihood Estimation\n",
    "\n",
    "Globular clusters are dense systems of stars that are found in almost all galaxies. From their red colors we know they are made of low-mass stars, emitting predominantly in the near infrared.\n",
    "\n",
    "Therefore, we expect that the K-band luminosity of a globular cluster is a good estimator of the number and the mass of its stars:\n",
    "\n",
    "$$\\Large M = \\Upsilon L_K $$\n",
    "\n",
    "If this relation holds, then knowing the proportionallity constant $\\Upsilon$, the characteristic *mass-to-light ratio* of globular clusters, allows us to estimate the masses of globular clusters by simply measuring their luminosity!\n",
    "\n",
    "## 1.1. The data\n",
    "\n",
    "Two independent research teams have studied the same sample of globular clusters. The first team (Lumis Raucity et al.), measured K-band absolute magnitudes (using 2MASS archival data and new distance estimates). The second team (Vela Masetti et al.), estimated the masses using velocity dispersion measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "K_absolute_magnitudes = np.genfromtxt(\"data/GC_MWG_absolute.csv\")\n",
    "masses = np.genfromtxt(\"data/GC_MWG_masses.csv\")\n",
    "log_masses = np.log10(masses)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(K_absolute_magnitudes, bins=20)\n",
    "plt.xlabel(\"Absolute K-band magnitude (mag)\")\n",
    "plt.ylabel(\"Number of globular clusters\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(log_masses, bins=20)\n",
    "plt.xlabel(\"$\\log M [M_\\odot]$\")\n",
    "plt.ylabel(\"Number of globular clusters\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(K_absolute_magnitudes, log_masses, \"ko\")\n",
    "plt.xlabel(\"Absolute K-band magnitude (mag)\")\n",
    "plt.ylabel(\"$\\log M [M_\\odot]$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The K-band luminosity is calculated (in solar units) using the formula:\n",
    "\n",
    "$$\\Large \\frac{L_K}{L_{K, \\odot}} = 10^{0.4\\left(M_{K,\\odot}-M_K\\right)} $$\n",
    "\n",
    "where $M_K$ is the $K$-band absolute magnitude, and $M_{K,\\odot}$ is that of the sun.\n",
    "\n",
    "Let's apply the above formula, and compare the measured masses against estimate assuming different values for the M/L ratio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_K_SOLAR = 3.29   # Blanton & Roweis (2007)\n",
    "\n",
    "\n",
    "def get_K_band_luminosity(absolute_magnitudes):\n",
    "    \"\"\"Compute the K-band luminosity (in solar units).\"\"\"\n",
    "    return 10.0 ** (0.4 * (M_K_SOLAR - absolute_magnitudes))\n",
    "\n",
    "def get_masses_from_K(absolute_magnitudes, mass_to_light_ratio):\n",
    "    \"\"\"Compute the mass from the K-band absolute magnitude and a M/L ratio.\"\"\"\n",
    "    K_band_luminosity = get_K_band_luminosity(absolute_magnitudes)\n",
    "    return mass_to_light_ratio * K_band_luminosity\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.log10(get_K_band_luminosity(K_absolute_magnitudes)), log_masses, \"ko\")\n",
    "plt.xlabel(\"$\\log L_K \\quad [L_{K, \\odot}]$\")\n",
    "plt.ylabel(\"$\\log M \\quad [M_\\odot]$\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "x_min, x_max = np.min(log_masses), np.max(log_masses)\n",
    "for ML_ratio in [0.7, 0.8, 0.9]:\n",
    "    predicted_log_masses = np.log10(get_masses_from_K(K_absolute_magnitudes, ML_ratio))\n",
    "    plt.plot(log_masses, predicted_log_masses, \".\", label=f\"assuming M/L = {ML_ratio:.2g}\")\n",
    "plt.plot([x_min, x_max], [x_min, x_max], \"k-\", label=\"1:1 line\")\n",
    "plt.ylabel(\"predicted $\\log M \\quad [M_\\odot]$\")\n",
    "plt.xlabel(\"measured $\\log M \\quad [M_\\odot]$\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just by looking at it we cannot constrain the M/L ratio. How can we estimate it?\n",
    "\n",
    "\n",
    "## 1.2. Constructing a likelihood function\n",
    "\n",
    "Our problem falls into the general case where we have a model connecting two quantities through a function of one parameter, $\\theta$ (in our case the M/L ratio):\n",
    "\n",
    "$$ \\Large y = f(x; \\theta) $$\n",
    "\n",
    "Therefore, if we get $N$ data, $(x_i, y_i)$ for $i \\in [1, 2, \\cdots, N]$ based on the model we would expect:\n",
    "\n",
    "$$\\Large y_i = f(x_i; \\theta) $$\n",
    "\n",
    "However, all observations are **subject to uncertainty**, and we need to model this as well. More often than not, uncertainties are fluctuations of a certain magnitude $\\sigma$ around 0, following the Gaussian distribution:\n",
    "\n",
    "$$\\Large y_i = f(x_i; \\theta) + \\epsilon_i $$\n",
    "\n",
    "where $\\epsilon_i$ is normally distributed:\n",
    "\n",
    "$$\\Large \\epsilon_i \\sim \\mathrm{Norm}(0, \\sigma)$$\n",
    "\n",
    "The $\\sigma$ is the standard deviation, or a typical difference between the observed $y_i$ and the intrinsic, true value $y_i$ which we **assume that is described by the model**.\n",
    "\n",
    "Consequently, according to our model, the probability to observe the $i$-th point's $y$-value, or the **datum likelihood** is\n",
    "\n",
    "$$\\Large\n",
    "P(x_i, y_i) = \\text{Norm}(y_i; f(\\theta; x_i), \\sigma) \n",
    "   = \\dfrac{1}{\\sqrt{2\\pi \\sigma^2}} \\exp \\left[{-\\dfrac{(y_i-f(x_i; \\theta))^2}{2\\sigma^2}} \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "\n",
    "expected = 3.5\n",
    "uncertainty = 0.5\n",
    "observed = 3.1\n",
    "distribution = st.norm(expected, uncertainty)\n",
    "x_plot = np.linspace(expected-5*uncertainty, expected+5*uncertainty, 101)\n",
    "y_plot = distribution.pdf(x_plot)\n",
    "plt.figure()\n",
    "for sigma in [1, 2, 3]:\n",
    "    x_in_sigma = np.linspace(expected-sigma*uncertainty, expected+sigma*uncertainty, 101)\n",
    "    y_in_sigma = distribution.pdf(x_in_sigma)\n",
    "    plt.fill_between(x_in_sigma, 0.0, y_in_sigma, ls=\"-\", edgecolor=\"k\", lw=2, facecolor=\"0.7\", alpha=0.2)\n",
    "plt.plot(x_plot, y_plot, \"k-\", lw=2, label=\"Distribution around $f(x_i)$\")\n",
    "plt.bar(observed, height=distribution.pdf(observed), color=\"r\", width=0.05, label=\"Observed ($y_i$)\")\n",
    "plt.ylim(ymin=0)\n",
    "plt.xlabel(\"$y$\")\n",
    "plt.ylabel(\"$P(y_i)$\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that our measurements are independent (the probability of $y_2$ does not depend on $y_1$), the overall probability to get our data, or **likelihood** (always **according to our model**) is the product of all likelihoods:\n",
    "\n",
    "$$\\Large L = \\prod_{i=1}^{N} P(x_i, y_i)$$\n",
    "\n",
    "Let's do the math...\n",
    "\n",
    "$$\\Large\n",
    "L = \\prod_{i=1}^{N} \\dfrac{1}{\\sqrt{2\\pi \\sigma^2}} \\exp \\left[{-\\dfrac{(y_i-f(x_i))^2}{2\\sigma^2}} \\right]\n",
    "$$\n",
    "\n",
    "$$\\Large\n",
    "L = \\left(\\dfrac{1}{\\sqrt{2\\pi \\sigma^2}}\\right)^N \\exp \\left[ -\\sum_{i=1}^{N} {\\dfrac{(y_i-f(x_i))^2}{2\\sigma^2}} \\right]\n",
    "$$\n",
    "\n",
    "$$\\Large\n",
    "L = \\left(\\dfrac{1}{\\sqrt{2\\pi \\sigma^2}}\\right)^N \\exp \\left[ -\\dfrac{1}{2\\sigma^2} \\sum_{i=1}^{N} (y_i-f(x_i))^2 \\right]\n",
    "$$\n",
    "\n",
    "Since the likelihood is a very small, but positive quantity, we can work in log-space:\n",
    "\n",
    "$$\\Large\n",
    "l = \\ln{L} = -\\frac{N}{2} \\ln\\left(2\\pi \\sigma^2\\right) -\\dfrac{1}{2\\sigma^2} \\sum_{i=1}^{N} (y_i-f(x_i))^2\n",
    "$$\n",
    "\n",
    "If we don't care about the normalization and the spread of the likelihood, we can ignore the constant terms in $l$:\n",
    "\n",
    "$$\\Large\n",
    "l' = -\\sum_{i=1}^{N} (y_i-f(x_i))^2\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(mass_to_light_ratio, absolute_magnitudes, observed_log_masses):\n",
    "    expected_masses = get_masses_from_K(absolute_magnitudes, mass_to_light_ratio=mass_to_light_ratio)\n",
    "    expected_log_masses = np.log10(expected_masses)\n",
    "    return -np.sum((expected_log_masses - observed_log_masses) ** 2.0)\n",
    "\n",
    "\n",
    "ml_ratios = np.linspace(0.5, 1.5, 101)\n",
    "log_likelihoods = [log_likelihood(ml, K_absolute_magnitudes, log_masses) for ml in ml_ratios]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(ml_ratios, np.exp(log_likelihoods), \"k.--\")\n",
    "plt.xlabel(\"Mass-to-light ratio ($M_\\odot / L_\\odot$)\")\n",
    "plt.ylabel(\"Likelihood (without constant terms)\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(ml_ratios, log_likelihoods, \"k.--\")\n",
    "plt.xlabel(\"Mass-to-light ratio ($M_\\odot / L_\\odot$)\")\n",
    "plt.ylabel(\"Log-likelihood (without constant terms)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*WARNING: The height and the width of the curves depends on the constant terms which, for now, we have ignored. The peak is in the correct position*:\n",
    "\n",
    "$$\\Large \\text{For } f(x) = A g(x) + B, \\text{ then } f'(x) = 0 \\Rightarrow A g'(x) = 0 \\Rightarrow g'(x) = 0 $$\n",
    "\n",
    "*Also, taking the $\\ln$ or $\\log$ of a positive function doesn't shift the minima/maxima:\n",
    "\n",
    "$$\\Large \\left[\\ln f(x) \\right]' = 0 \\Rightarrow \\dfrac{f'(x)}{f(x)} = 0 \\Rightarrow f'(x) = 0 $$\n",
    "\n",
    "\n",
    "\n",
    "## 1.3. Maximizing the likelihood analytically\n",
    "\n",
    "We can get the best-fitting values of model parameters by maximizing the likelihood function:\n",
    "\n",
    "$$\\Large \\frac{\\partial L}{\\partial \\theta_i} = 0 \\qquad \\mathrm{or} \\qquad \\frac{\\partial l}{\\partial \\theta_i} = 0$$\n",
    "\n",
    "or it's log-version:\n",
    "\n",
    "$$\\Large \\frac{\\partial l}{\\partial \\theta_i} = 0 $$\n",
    "\n",
    "\n",
    "for all parameters $\\theta_i$ of the model. Typically, we need to also ensure that it's not a minimum:\n",
    "\n",
    "$$\\Large \\frac{\\partial^2 L}{\\partial \\theta_i^2}(\\theta_i') < 0 $$\n",
    "\n",
    "\n",
    "## 1.4. Maximizing the likelihood: numerically\n",
    "\n",
    "An analytical solution might not exist. No worries, we can always use the numerical approach which works pretty well and fast for most cases. Note that `scipy` provides powerful methods to **minimize** functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "\n",
    "def function_to_minimize(parameter):\n",
    "    return -log_likelihood(parameter, absolute_magnitudes=K_absolute_magnitudes, observed_log_masses=log_masses)\n",
    "\n",
    "\n",
    "minimization_outcome = minimize_scalar(function_to_minimize, bounds=[0.0, 3.0])\n",
    "print(\"Minimization outcome:\")\n",
    "print(minimization_outcome)\n",
    "\n",
    "solution = minimization_outcome.x\n",
    "true_ML = 0.822                         # Kovlakas et al. 2021\n",
    "\n",
    "print()\n",
    "print(f\"Best-fitting M/L ratio : {minimization_outcome.x:.4f}\")\n",
    "print(f\"True value             : {true_ML:.4f}\")\n",
    "print(f\"Relative difference    : {100.0*(solution - true_ML) / true_ML:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3><u>**In-class discussion: would we get the same result by fitting with ordinary least-squares?**</u><font>\n",
    "\n",
    "<details>\n",
    "<summary><b>[Spoiler]</b></summary>\n",
    "<br>\n",
    "A least-squares fit is what we did! We minimized -$f(\\theta)$ where $f(\\theta)$ is the negative sum of square differences between the prediction (from $\\theta$) and the observations!\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3><u>**In-class discussion: if yes, is it because the data appear to have a linear correlation?**</u><font>\n",
    "\n",
    "<details>\n",
    "<summary><b>[Spoiler]</b></summary>\n",
    "<br>\n",
    "The fact that we perform a least-squares fit (numerically rather than analytically) is a consequence of the likelihood function, not the form of the data! The assumptions of least-squares method (e.g., linear parameters in the model, Gaussian residuals around 0, independent samples, etc.) are the same with the ones we made!\n",
    "\n",
    "It's not difficult to imagine cases where the there is linear correlation, but the likelihood would have to be different: number of stars vs. mass of a galaxy.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Hypothesis testing\n",
    "\n",
    "**Definition**\n",
    "\n",
    "Hypothesis testing is the process of testing an assumption regarding a parameter of a population, using a sample from the latter.\n",
    "\n",
    "> Example: Verifying a model for the mass of globular clusters (GC)\n",
    "\n",
    "## 2.1. The theoretical model\n",
    "\n",
    "Globis & Clusterton (2022) used hydrodynamical galaxy simulations to model the formation of globular clusters (GC) in a galaxy like the Milky Way. They found that the masses of the synthetic GCs are described by a log-normal distribution. Namely, the logarithm of the masses are normally distributed:\n",
    "\n",
    "$$\\large \\log_{10} \\left(\\frac{M}{M_\\odot}\\right) \\sim \\mathcal{N}(5.5, 1) $$\n",
    "\n",
    "meaning that the GCs masses peak at $10^{5.5} M_\\odot \\simeq 3.2\\times 10^5 M_\\odot$ and the typical scatter is $1\\,\\mathrm{dex}$ (one order of magnitude).\n",
    "\n",
    "Let's see this the model along with the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "\n",
    "model_mean = 5.5\n",
    "model_std = 1.0\n",
    "\n",
    "logm_for_plot = np.linspace(min(log_masses)-1, max(log_masses)+1, 100)\n",
    "model_prob_for_plot = st.norm(model_mean, model_std).pdf(logm_for_plot)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(log_masses, bins=20, density=True, label=\"Data\")\n",
    "plt.plot(logm_for_plot, model_prob_for_plot, \"r-\", lw=2, label=\"Model\")\n",
    "plt.xlabel(\"$\\log M [M_\\odot]$\")\n",
    "plt.ylabel(\"Number of globular clusters\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_mean = np.mean(log_masses)\n",
    "sample_std = np.std(log_masses)\n",
    "\n",
    "print(f\"MODEL:  Mean = {model_mean:.2f} | Std = {model_std:.2f}\")\n",
    "print(f\"SAMPLE: Mean = {sample_mean:.2f} | Std = {sample_std:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3><u>**In-class discussion: is the sample mean close to the model's value?**</u><font>\n",
    "\n",
    "_Discuss with your teammate, then report._\n",
    "\n",
    "<details>\n",
    "<summary><b>[Spoiler]</b></summary>\n",
    "<br>\n",
    "There is no right answer... it is subjective. Our goal here is to quantify this \"subjectiveness\"!\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3><u>**In-class discussion: does the standard deviation give a sense of how close the mean values are?**</u><font>\n",
    "\n",
    "_Discuss with your teammate, then report._\n",
    "\n",
    "<details>\n",
    "<summary><b>[Spoiler]</b></summary>\n",
    "<br>\n",
    "Not exactly. The standard deviation describes the scatter of the data. Itself does not say much about the deviation of the sample mean from the model's expectation.\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Standard error of the mean\n",
    "\n",
    "Whether the mean values are close depends also on the sample size. The larger it is, the more accurate our estimate on the mean is, and we would expect it to converge to the mean of the underlying population (and that of the model if it is correct). \n",
    "\n",
    "For normally distributed data the **standard deviation of the mean** scales as:\n",
    "\n",
    "$$ \\large \\sigma_{\\bar{x}} = \\frac{\\sigma}{\\sqrt{N}} $$\n",
    "\n",
    "where $\\sigma$ is the population standard deviation and $N$ is the sample size.\n",
    "\n",
    "In most cases, the population deviation is unknown. For this reason, we use the same sample to estimate it, calculating the *sample standard deviation $s$*. The standard deviation of the sample mean is called **standard error on the mean**:\n",
    "\n",
    "$$ \\large s_{\\bar{x}} = \\frac{s}{\\sqrt{N}} $$\n",
    "\n",
    "The sample mean is considered to be normally distributed (see *Central Limit Theorem* below), and therefore we can calculate the number of standard errors the sample mean is away from the theoretical value, or the **sigmas**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sem = st.sem(log_masses)\n",
    "print(f\"Standard error of the mean = {sample_sem:.2f}\")\n",
    "print(f\"Sigma's of difference      : {(model_mean-sample_mean) / sample_sem:.2f}\")\n",
    "\n",
    "x_plot = np.linspace(sample_mean - 5 * sample_sem, sample_mean + 5 * sample_sem, 100)\n",
    "mean_distribution = st.norm(sample_mean, sample_sem)\n",
    "y_plot = mean_distribution.pdf(x_plot)\n",
    "plt.figure()\n",
    "plt.plot(x_plot, y_plot, \"k-\", lw=2, label=\"N(mean, SEM)\")\n",
    "plt.axvline(sample_mean, ls=\"-\", color=\"b\", label=\"Sample mean\")\n",
    "plt.axvline(model_mean, ls=\"--\", lw=2, color=\"r\", label=\"Model mean\")\n",
    "for sigmas in [1, 2, 3]:\n",
    "    plt.axvspan(sample_mean - sigmas*sample_sem, sample_mean + sigmas*sample_sem, color=\"b\", alpha=0.1)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.ylim(ymin=0.0)\n",
    "plt.xlabel(\"$\\log M [M_\\odot]$\")\n",
    "plt.ylabel(\"PDF of the sample mean\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3><u>**In-class discussion: is the means' difference small enough to accept the model?**</u><font>\n",
    "\n",
    "_Discuss with your teammate, then report._\n",
    "\n",
    "<details>\n",
    "<summary><b>[Spoiler]</b></summary>\n",
    "<br>\n",
    "Still subjective! But we are closer to quantifying this \"subjectiveness\"!\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. When to reject a model...\n",
    "\n",
    "One might argue that if the theoretical mean is too extreme, either **too low** or **two high**, we should **reject the hypothesis that the model describes the data at hand**. \n",
    "\n",
    "Therefore we can calculate from the sample mean distribution what is the probability of such extreme values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_plot = np.linspace(sample_mean - 5 * sample_sem, sample_mean + 5 * sample_sem, 100)\n",
    "\n",
    "diff = abs(sample_mean - model_mean)\n",
    "xx_before = np.linspace(sample_mean - 5 * sample_sem, sample_mean - diff, 100)\n",
    "xx_after = np.linspace(sample_mean + diff, sample_mean + 5 * sample_sem, 100)\n",
    "\n",
    "mean_distribution = st.norm(sample_mean, sample_sem)\n",
    "y_plot = mean_distribution.pdf(x_plot)\n",
    "\n",
    "plt.figure()\n",
    "plt.fill_between(xx_before, mean_distribution.pdf(xx_before), 0, color=\"r\", ec=\"none\", alpha=0.5, label=\"Area more extreme\")\n",
    "plt.fill_between(xx_after, mean_distribution.pdf(xx_after), 0, color=\"r\", ec=\"none\", alpha=0.5)\n",
    "plt.plot(x_plot, y_plot, \"k-\", lw=2, label=\"N(mean, sem)\")\n",
    "plt.axvline(sample_mean, ls=\"-\", color=\"b\", label=\"Sample mean\")\n",
    "plt.axvline(model_mean, ls=\"--\", lw=2, color=\"r\", label=\"Model mean\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.ylim(ymin=0.0)\n",
    "plt.xlabel(\"$\\log M [M_\\odot]$\")\n",
    "plt.ylabel(\"PDF of the sample mean\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cumulative distribution function is\n",
    "\n",
    "$$ \\large F(x) = \\int\\limits_{-\\infty}^{x} f(x') dx' $$\n",
    "\n",
    "The \"area more exteme\" is \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\large p   \n",
    "    &= \\large 1 - \\textrm{(area between)} = \\\\\n",
    "    &= 1 - \\int\\limits_{m-d}^{m+d} f(x') dx' = \\\\\n",
    "    &= 1 - \\left(\\int\\limits_{-\\infty}^{m+d} f(x')dx' - \\int\\limits_{\\infty}^{m-d} f(x')dx' \\right) = \\\\\n",
    "    &= \\large 1 - \\left[F(m+d) - F(m-d)\\right]\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "which in our case is..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_more_extreme = 1 - (mean_distribution.cdf(sample_mean+diff) - mean_distribution.cdf(sample_mean-diff))\n",
    "print(f\"Area more extreme, p = {area_more_extreme:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, there is $\\sim 7\\%$ probability, or **$p$-value**, to reject this model even if it is correct. *Can we risk it*? It is **our choice** to consider our \"threshold\" or **significance level**!\n",
    "\n",
    "If we had decided **before looking at the data** to use a 5% threshold, then our conclusion is that \n",
    "\n",
    "> *we do not reject the model, with a significance level of 5%\".*\n",
    "\n",
    "#### IMPORTANT: we didn't accept the model\n",
    "The analysis above does not validate the model!!! The only thing we verified is that **one property**, the mean value the data is not that different than what we would expect from the model. If it was, then we would have reasons to no believe the model. For example, if we had found $p=0.0001$ we would **reject the model** given the sample at hand.\n",
    "\n",
    "\n",
    "#### IMPORTANT: 7% is not the probablity for the hypothesis (or model) to be correct\n",
    "There are infinite other models under which the $p$-value above would be above our threshold. For example, $N(5.5, 0.101)$, $N(5.51, 0.1)$, ...\n",
    "\n",
    "### Choosing the significance level\n",
    "\n",
    "There is no rule on what the significance level should be. Just that is should be decided before looking at the data, to avoid, **as humans, biasing our conclusions by relaxing our criteria for models we like, or making it harder for models we don't like!**\n",
    "\n",
    "In Astronomy, $2 + 2 \\simeq 5$, so we often use 0.5, 1 or 5%. In Nuclear physics and precision experiments often $10^{-7}$ or $10^{-10}$ are used!\n",
    "\n",
    "Since the $p$-value is connected to the number of sigmas in difference, often we refer to *sigmas* instead of a significance level. It is shorter to say, and it is easier to \"imagine\" it in plots with error bars and distributions. For example:\n",
    "\n",
    "| Sigmas | Probability (inside) | Probability (outside) |\n",
    "| --- | --- | --- |\n",
    "|  1 | 0.68 | 0.32 |\n",
    "|  2 | 0.954 | 0.046 |\n",
    "|  3 | 0.9973 | 0.0027 |\n",
    "|  5 | 0.9999994 | 0.0000006 |\n",
    "|  8 | 0.9999999999999987 | 0.0000000000000013"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3><u>**In-class discussion: what does it mean to have a 10-sigma particle detection? Is it good that the significance level is very small?**</u><font>\n",
    "\n",
    "_Discuss with your teammate, then report._\n",
    "\n",
    "<details>\n",
    "<summary><b>[Spoiler]</b></summary>\n",
    "<br>\n",
    "Never judge before considering what is the null hypothesis! Previously, we checked a specific model, and therefore our null hypothesis was that the data agree with it (at least their mean).\n",
    "\n",
    "In particle detectors, the null hypothesis is usually: the signal was noise! There we test whether the data came about randomly. Rejecting that a signal is noise with significance level of 0.0000000000000000000015% is not bad at all!\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. In the language of Statistics: *Hypothesis testing*\n",
    "\n",
    "> **Step 1**: We define the **null hypothesis** or the statement that we will test (a model or random outcome)\n",
    "\n",
    "> **Step 2**: We decide on a **significance level** - or what is the \"probability for being wrong in rejecting the null hypothesis\" that we are comfortable with?\n",
    "\n",
    "> **Step 3**: The **statistic** - a quantitiy that is computed on our *sample* assuming the *hypothesis is true*\n",
    "\n",
    "> **Step 4**: **$p$-value** OR **critical value**: compute the \"probability of being wrong\" or the value of the statistic based on which we will reject the hypothesis or not\n",
    "\n",
    "> **Step 5**: the decision!\n",
    "\n",
    "\n",
    "### Step 1. We define the null hypothesis\n",
    "\n",
    "> $H_0$: the mean value of the decimal logarithm of the masses of Milky Way GCs is consistent with the model\n",
    "\n",
    "### Step 2. We decide on a significance level\n",
    "\n",
    "This is the probability for rejecting the null hypothesis if it is true - the \"probability of being wrong\" if we reject the hypothesis at the end.\n",
    "\n",
    "> Let's take a significance level of $5\\%$, i.e. $a = 0.05$\n",
    "\n",
    "### Step 3. The statistic, $Z$-score\n",
    "\n",
    "#### Note: since we know it, we use the population standard deviation\n",
    "\n",
    "In order to decide whether the sample mean is consistent with the model's prediction, we must compute the **distribution of the sample mean given that the model is correct.**\n",
    "\n",
    "For $N$ observations $x_i$ the sample mean, $\\bar{x}$ is\n",
    "\n",
    "$$ \\bar{x} = \\frac{1}{N} \\sum\\limits_{i=1}^{N} x_i$$\n",
    "\n",
    "For normally distributed observations, $x_i \\sim \\mathcal{N}(\\mu, \\sigma)$, it is known that the sample mean is also normally distributed with mean equal to the population mean ($\\mu$) and standard deviation equal to the population standard deviation ($\\sigma$) devided by the square root of the size of the sample ($N$):\n",
    "\n",
    "$$ \\bar{x} \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma^2}{N}\\right)$$\n",
    "\n",
    "...called *standard deviation of the mean*:\n",
    "\n",
    "$$ \\sigma_{\\bar{x}} = \\frac{\\sigma}{\\sqrt{N}}$$\n",
    "\n",
    "Therefore the probability density function (PDF) of the sample mean is:\n",
    "\n",
    "$$f(\\bar{x}) = \\frac{1}{\\sqrt{2\\pi \\ \\sigma_{\\bar{x}}^2}} \\exp\\left[-\\frac{\\left(\\bar{x} - \\mu\\right)^2}{2 \\ \\sigma_{\\bar{x}}^2}\\right]$$\n",
    "\n",
    "Because of the ability to shift and scale the normal distribution, the quantity\n",
    "\n",
    "$$ Z = \\frac{\\bar{x} - \\mu}{\\sigma_{\\bar{x}}} $$\n",
    "\n",
    "follows the standard normal distribution (i.e. mean value $0$ and standard deviation $1$):\n",
    "\n",
    "$$ f(Z) = \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{1}{2}Z^2}$$\n",
    "\n",
    "Therefore, by just computing the $Z$ *score* of our sample, $z$, we can easily use tables for the normal distribution or code to quickly compute the probability at which $Z$ is below or above a specific value.\n",
    "\n",
    "We call this value $Z$ *statistic* or *score* and it used whenever the quantity we use to test the hypothesis is normally distributed.\n",
    "\n",
    "### Step 4. $p$-value and critical value(s) for the statistic\n",
    "\n",
    "\n",
    "<div><img src=\"images/two_tailed.png\" width=\"500\"/></div>\n",
    "\n",
    "\n",
    "Because of the null hypothesis, we must convert the statement \"*consistent with...*\" to a mathematical statement. In this example, we can consider that the sample mean is inconsistent with the model prediction if its significantly lower or higher (see *two tail test* instead of *one tail test*).\n",
    "\n",
    "Therefore, the Type I error is equal to probability that the $Z$ score deviates more than the absolute deviation of the score for the sample at hand:\n",
    "\n",
    "$$ p = P(Z > |z|) + P(Z < -|z|) $$\n",
    "\n",
    "Using the symmetry of normal distribution's PDF and the fact that $P({\\rm A}) + P({\\rm not\\ A}) = 1$, we arrive at\n",
    "\n",
    "$$ p = \\cdots = 2 \\left(1 - P\\left(Z < |z|\\right)\\right) = \\cdots = 2 P(Z < -|z|)$$\n",
    "\n",
    "or simply,\n",
    "\n",
    "$$ p = 2 \\Phi(-|z|) $$\n",
    "\n",
    "where $\\Phi(z)$ is the CDF of the standard normal distirbution.\n",
    "\n",
    "If we find $p < a = 0.05$ then we reject the null hypothesis.\n",
    "\n",
    "Alternatively, we can set **critical** values of the $Z$ score that correspond to the significance level of choice. As rejection should occur either for higher or lower values (two-tailed test), we find two critical values corresponding to $a/2$ probability:\n",
    "\n",
    "$$ Z_{\\rm crit,1} = \\Phi^{-1}\\left(\\frac{a}{2}\\right) = -1.96 $$\n",
    "\n",
    "$$ Z_{\\rm crit,2} = \\Phi^{-1}\\left(1 - \\frac{a}{2}\\right) = +1.96 $$\n",
    "\n",
    "Because of the symmetry of the normal distribution we could also compute a critical value for the absolute $Z$ score:\n",
    "\n",
    "$$ |Z|_{\\rm crit} = 1.96 $$\n",
    "\n",
    "This is equivalent to asking *how many **sigmas** away from the model prediction can the measured value be in order to reject the null hypotheis?* Astronomers are used to use the $\\sigma$ term: \"we reject the hypothesis on a $2\\sigma$ significance level!\"\n",
    "\n",
    "### Step 5. Decision\n",
    "\n",
    "Now that we defined all the steps, we can apply it on the data. In the following code, we compute the statistic and print the outcome based on $p$-value. Alternatively we can use the critical value.\n",
    "\n",
    "## 2.5. $Z$-test \n",
    "\n",
    "Let's do the above with code, assuming we know the population standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set alpha and compute the critical value(s)\n",
    "alpha = 0.05\n",
    "print(\"Significance level: {:7.3f}\".format(alpha))\n",
    "\n",
    "# compute the p-value and report the result\n",
    "sample_size = len(log_masses)\n",
    "sample_mean = np.mean(log_masses)\n",
    "stddev_mean = model_std / (sample_size ** 0.5)\n",
    "z_score = (sample_mean - model_mean) / stddev_mean\n",
    "pvalue = 2 * st.norm(0, 1).cdf(-abs(z_score))\n",
    "\n",
    "print(\"Sample mean       : {:7.3f}\".format(sample_mean))\n",
    "print(\"Standard error    : {:7.3f}\".format(stddev_mean))\n",
    "print(\"Sample Z-score    : {:7.3f}\".format(z_score))\n",
    "print()\n",
    "print(\"p-value           : {:7.3g}\".format(pvalue))\n",
    "\n",
    "if pvalue <  alpha:\n",
    "    print(\"    ...we reject the null hypothesis. ****\")\n",
    "else:\n",
    "    print(\"    ...we cannot reject the null hypothesis. ****\")\n",
    "    \n",
    "print()\n",
    "\n",
    "# alternatively we could compute the critical value and base our outcome on it\n",
    "z_critical = abs(st.norm.ppf(alpha / 2.0))\n",
    "print(\"Critical values   : {:7.3f} and {:.3f}\".format(-z_critical, z_critical))\n",
    "if abs(z_score) > abs(z_critical):\n",
    "    print(\"    ...we reject the null hypothesis. ****\")\n",
    "else:\n",
    "    print(\"    ...we cannot reject the null hypothesis. ****\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 $t$-test\n",
    "\n",
    "Above we used the theoretical value of $\\sigma$ to calculate the $Z$-score. We **assumed** that we know the standard deviation of the population! In most cases, we don't! Instead, we **estimate** the population parameter $\\sigma$ from the standard deviation in the sample $s$.\n",
    "\n",
    "*Caveat: we are using the same values to calculate the mean and the standard deviation - therefore there is one less degree of freedom in the statistic*:\n",
    "\n",
    "$$ \\large \\text{dof} = n - 1 $$\n",
    "\n",
    "> Is the mean value of a sample equal to the population mean (without knowing the population standard deviation)?\n",
    "\n",
    "The distribution of the sample mean now follows the Student's $t$-distribution.\n",
    "\n",
    "The corresponding statistic is\n",
    "\n",
    "$$ \\large t = \\frac{\\bar{x} - \\mu}{s / \\sqrt{n}} $$\n",
    "\n",
    "where $s$ is the sample standard deviation that takes the place of the population standard deviation in the $Z$-test we saw previously. The $t$-distribution is similar to the Gaussian but has 'heavier' tails when the sample size is small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_plot = np.linspace(sample_mean - 5 * sample_sem, sample_mean + 5 * sample_sem, 100)\n",
    "\n",
    "dof = len(log_masses) - 1\n",
    "Z_dist = st.norm(loc=sample_mean, scale=sample_sem)\n",
    "t_dist = st.t(dof, loc=sample_mean, scale=sample_sem)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "for inlog, subplot_index in zip([False, True], [1, 2]):\n",
    "    plt.subplot(1, 2, subplot_index)\n",
    "    plt.plot(x_plot, t_dist.pdf(x_plot), \"r\", label=\"t-Student distribution\")\n",
    "    plt.plot(x_plot, Z_dist.pdf(x_plot), \"b\", label=\"Gaussian (Z) distribution\")\n",
    "    plt.xlabel(\"Sample mean\")\n",
    "    plt.ylabel(\"Probability density\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    if inlog:\n",
    "        plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "t_score = (sample_mean - model_mean) / sample_sem\n",
    "p_value = 2 * st.t(dof).cdf(-abs(t_score))  # implied that loc=0, scale=1\n",
    "\n",
    "print(\"Sample t-score    : {:7.3f}\".format(t_score))\n",
    "print(\"p-value           : {:7.3g}\".format(p_value))\n",
    "\n",
    "if pvalue <  alpha:\n",
    "    print(\"    ...we reject the null hypothesis. ****\")\n",
    "else:\n",
    "    print(\"    ...we cannot reject the null hypothesis. ****\")\n",
    "    \n",
    "print()\n",
    "\n",
    "# alternatively we could compute the critical value and base our outcome on it\n",
    "t_critical = abs(st.t(dof).ppf(alpha / 2.0))\n",
    "print(\"Critical values   : {:7.3f} and {:.3f}\".format(-t_critical, t_critical))\n",
    "if abs(t_score) > abs(t_critical):\n",
    "    print(\"    ...we reject the null hypothesis. ****\")\n",
    "else:\n",
    "    print(\"    ...we cannot reject the null hypothesis. ****\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3><u>**In-class discussion: how and why did $p$ and critical values change?**</u><font>\n",
    "\n",
    "_Discuss with your teammate, then report._\n",
    "\n",
    "<details>\n",
    "<summary><b>[Spoiler]</b></summary>\n",
    "<br>\n",
    "The $p$-value is smaller because the sample standard deviation is smaller than the model one, leading to smaller $\\sigma/\\sqrt{N}$ too. Consequently, the difference between the means is statistically more significant compared to the $Z$-test!\n",
    "    \n",
    "For the same significance level, the critical values of the $t$-statistic have larger absolute values than the $Z$-statistic because the $t$-Student distribution is broader. In principle, larger differences between the means are tolerated when we don't know the standard deviation.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directly performing the t-student test..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic, pvalue = st.ttest_1samp(log_masses, model_mean)\n",
    "print(\"Statistic = {:.3g}\".format(statistic))\n",
    "print(\"p-value   = {:.3g}\".format(pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7. The Central Limit Theorem\n",
    "\n",
    "In the above example we assumed that the mean of the sample is normally-distributed, i.e. following the Gaussian distribution. This is often the case, at least with some approximation due to the **Central Limit Theorem**:\n",
    "\n",
    "> the sampling distribution of the sample mean approaches a normal distribution as the sample size gets larger, no matter what the shape of the population distribution.\n",
    "\n",
    "Let's take the *arcsine* distribution which does not look like a Gaussian at all..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution = st.arcsine()\n",
    "xx = np.linspace(0.0001, 1.0-0.0001, 1000)\n",
    "plt.figure()\n",
    "plt.plot(xx, distribution.pdf(xx))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![...](images/thats-just-not-normal.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_of_iterations = 10000\n",
    "n_of_examples = 3\n",
    "hist_colors = plt.colormaps.get_cmap(\"cividis\")(np.linspace(0, 1, n_of_examples))\n",
    "sample_sizes = [1000, 30, 3]\n",
    "\n",
    "for sample_size in sample_sizes:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5), constrained_layout=False)\n",
    "    plt.suptitle(f\"Sample size = {sample_size}\")   \n",
    "    ax1.set_title(f\"The first {n_of_examples} samples and their mean\")\n",
    "    ax2.set_title(f\"The distribution of the sample mean\")\n",
    "    \n",
    "    examples_shown = 0\n",
    "    sample_means = []\n",
    "    for iteration in range(n_of_iterations):\n",
    "        sample = distribution.rvs(size=sample_size)\n",
    "        sample_mean = np.mean(sample)\n",
    "        sample_means.append(sample_mean)\n",
    "        \n",
    "        if examples_shown < n_of_examples:\n",
    "            ax1.hist(sample, bins=10, density=True, histtype=\"step\",\n",
    "                     color=hist_colors[iteration], alpha=0.7, lw=2, label=f\"Iteration {iteration+1}\")\n",
    "            ax1.axvline(sample_mean, color=hist_colors[iteration], lw=3, alpha=0.7)\n",
    "            examples_shown += 1\n",
    "    ax1.legend(loc=\"upper left\")\n",
    "\n",
    "    ax2.hist(sample_means, bins=\"fd\", histtype=\"step\", density=True, color=\"C1\", lw=2)\n",
    "    xx = np.linspace(min(sample_means), max(sample_means), 200)\n",
    "    ax2.plot(xx, st.norm.pdf(xx, distribution.mean(), distribution.std() / sample_size**0.5), lw=2, color=\"C9\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8. Distribution tests\n",
    "\n",
    "###  Normality test\n",
    "\n",
    "Above we used our eyes to see the validity of the Central Limit Theorem. But are eyes, and our plotting choices (e.g., bin sizes) play tricks! Instead, we can test whether a sample follows a known distribution.\n",
    "\n",
    "In addition, in the hypothesis test, we assumed that the data are normally distributed. This is an expectation from the theory, and in could be tested independently of the parameters of the Gaussian distribution.\n",
    "\n",
    "When our analysis depends on the \"normality\" of a distribution, it is better the perform a hypothesis test for exactly that - a **noramlity test**!\n",
    "\n",
    "Here we use the **Shapiro-Wilk test for normality** (but it's not the only one out there) to test whether the log-masses of the GCs are following the normal distribution.\n",
    "\n",
    "We **always have to ask which one is the null hypothesis test when using them as a black box**. For Shapiro-Wilk is:\n",
    "\n",
    ">  $H_0$: the sample came from a normally distributed population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.shapiro(log_masses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arbitrary distribution test: the K-S test\n",
    "\n",
    "Note that a normality test, is very specific to the distribution we check against (Gaussin), but not it's parameters. To check for agreement with any distribution, the **Kolmogorov-Smirnov** test can be used.\n",
    "\n",
    "> $H_0$: the sample is drawn from the reference distribution\n",
    "\n",
    "The test is measuring the maximum distance between two cumulative distribution functions (from the sample and a model/another sample), which is called $D$ statistic. Depending on the number of samples, the $D$ statistics corresponds to a $p$-value. Let's see how it looks for our example, against the model distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(min(log_masses)-1, max(log_masses)+1, 10000)\n",
    "xx = (bins[1:] + bins[:-1]) / 2.0\n",
    "\n",
    "model_cdf = st.norm.cdf(xx, loc=model_mean, scale=model_std)\n",
    "plt.figure()\n",
    "sample_cdf, _, _ = plt.hist(log_masses, bins=bins, density=True, cumulative=1, \n",
    "                            histtype=\"step\", label=\"Sample CDF\")\n",
    "\n",
    "# where is the maximum difference between the model and sample CDFs?\n",
    "where_max_d = np.argmax(np.abs(model_cdf - sample_cdf))\n",
    "\n",
    "# find the height of the CDFs at their furthest point\n",
    "D1, D2 = model_cdf[where_max_d], sample_cdf[where_max_d]\n",
    "\n",
    "# the maximum difference\n",
    "D = abs(D1 - D2)\n",
    "\n",
    "plt.plot(xx, model_cdf, label=\"Model CDF\")\n",
    "plt.plot([xx[where_max_d]]*2, [D1, D2], \"k:\", label=\"D={:.4g}\".format(D))\n",
    "plt.xlabel(\"$\\log M [M_\\odot]$\")\n",
    "plt.ylabel(\"Cumulative distribution function\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform the K-S test\n",
    "model_distribution = st.norm(model_mean, model_std)\n",
    "st.kstest(log_masses, model_distribution.cdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3><u>**In-class discussion: Why do we get a different $p$-value with the K-S test?**</u><font>\n",
    "\n",
    "_Discuss with your teammate, then report._\n",
    "\n",
    "<details>\n",
    "<summary><b>[Spoiler]</b></summary>\n",
    "<br>\n",
    "It's not that one method is incorrect! The questions are different, i.e., we tested different hypotheses!\n",
    "\n",
    "With the Shapiro-Wilk test we tested if the data are normally distributed, whatever the mean and standard deviation. With the K-S test we tested if the data follow a very specific normal distribution with a defined mean and standard deviation.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.9. Dependence/independence of random variables\n",
    "Sometimes we want to test whether two quantities are (un)correlated, or *(in)dependent*. This is useful for \n",
    "* confirming a model predicting that such a correlation exists\n",
    "* predicting a quantity (e.g., 'y' from 'x')\n",
    "* verify a monotonic relation between two quantities\n",
    "\n",
    "## Linear correlation tests\n",
    "\n",
    "In the begining of the chapter, we assumed that the K-band luminosity and the mass are correlated, and therefore the logarithm of the mass is linearly correlated with the absolute magnitude:\n",
    "\n",
    "$$\\Large \n",
    "    \\begin{cases} \n",
    "        M &= \\Upsilon L_K \\\\\n",
    "        \\dfrac{L}{L_\\odot} &= 10^{0.4\\left(M_{K,\\odot}-M_K\\right)}\n",
    "    \\end{cases}\n",
    "    \\Rightarrow\n",
    "    \\log (M/M_\\odot) = a M_K + b\n",
    "$$\n",
    "where the $a$ and $b$ parameters are expressions of the mass-to-light ratio, the solar K-band absolute magnitude, etc.\n",
    "\n",
    "We can perform an ordinary least-squares fit to get the best-fitting values of $a$ and $b$. The function `linregress` provided by the `scipy` package can be used. It also returns a $p$-value based on the result!  \n",
    "\n",
    "The documentation reports:\n",
    "> The p-value for a hypothesis test whose null hypothesis is that the slope is zero, using Wald Test with t-distribution of the test statistic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = st.linregress(x=K_absolute_magnitudes, y=log_masses)\n",
    "\n",
    "slope, intercept, rvalue, pvalue, slope_stderr = res\n",
    "intercept_stderr = res.intercept_stderr                # for compatibility this value is extracted like this\n",
    "\n",
    "print(\"FIT RESULTS:\")\n",
    "print(\"    slope          : {:.2f} +/- {:.2f}\".format(slope, slope_stderr))\n",
    "print(\"    intercept      : {:.2f} +/- {:.2f}\".format(intercept, intercept_stderr))\n",
    "print(\"    corr. coeff. R : {:.6f}\".format(rvalue))\n",
    "print(\"    R squared      : {:.6f}\".format(rvalue**2.0))\n",
    "print(\"    p-value        : {:.6g}\".format(pvalue))\n",
    "\n",
    "x_plot = np.array([min(K_absolute_magnitudes), max(K_absolute_magnitudes)])\n",
    "y_plot = slope * x_plot + intercept\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "plt.plot(K_absolute_magnitudes, log_masses, \"ko\", mfc=\"none\", label=\"Data\")\n",
    "plt.plot(x_plot, y_plot, \"r-\", label=\"Fit: y = {:.3g} x {:+.3g}\".format(slope, intercept))\n",
    "plt.xlabel(\"K-band absolute magnitude (mag)\")\n",
    "plt.ylabel(\"$\\log(M/M_\\odot)$\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "\n",
    "residuals = log_masses - (slope * K_absolute_magnitudes + intercept)\n",
    "# plt.figure(constrained_layout=True)\n",
    "plt.subplot(223)\n",
    "plt.plot(K_absolute_magnitudes, residuals, \"ko\")\n",
    "plt.xlabel(\"K-band absolute magnitude (mag)\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.subplot(224)\n",
    "plt.hist(residuals, bins=\"fd\", histtype=\"step\")\n",
    "plt.xlabel(\"Residuals\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson correlation coefficient:\n",
    "\n",
    "$$ \\large \\rho = \\dfrac{\\mathrm{cov}\\left(X, Y\\right)}{\\sigma_X \\sigma_Y} $$\n",
    "\n",
    "For a sample:\n",
    "\n",
    "$$ \\large\n",
    "    r = \\dfrac{\n",
    "              \\sum\\limits_{i=1}^{n}\\left(x_i - \\bar{x}\\right)\\left(y_i - \\bar{y}\\right)\n",
    "              }\n",
    "              {\n",
    "              \\sqrt{\n",
    "              \\sum\\limits_{i=1}^{n}\\left(x_i - \\bar{x}\\right)^2\n",
    "              \\sum\\limits_{i=1}^{n}\\left(y_i - \\bar{y}\\right)^2\n",
    "              }\n",
    "              }\n",
    "$$\n",
    "\n",
    "- 0: no correlation. \n",
    "- 1: perfect correlation\n",
    "- -1: perfect anti-correlation.\n",
    "\n",
    "The square of $r$, usually refered as **R-squared** in the literature, is the *percentage of explained variance through the linear correlation*.\n",
    "\n",
    "Therfore, a $p$-value smaller than our significance level, means that **we reject the hypothesis that the slope is 0**, which can be rephrased as **we cannot reject the hypothesis that there is a linear correlation**.\n",
    "\n",
    "**Warning**: this doesn't mean that we accept that the correlation is linear. We get the above result *assuming linear correlation*!\n",
    "\n",
    "\n",
    "### If we do not need to fit, we can use the `pearsonr` function to perform the hypothesis test\n",
    "\n",
    "**Warning**: this does not alleviate the caveat that the correlation might not be linear!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.pearsonr(K_absolute_magnitudes, log_masses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monotonicity test\n",
    "\n",
    "Sometimes a linear correlation does not exist! For example, if we had no intuition about the connection between the K-band absolute magnitudes and masses of globular clusters, plotting them we would see a trend! The higher the magnitude, the lower the mass.\n",
    "\n",
    "The Pearson correlation test would... not be very appropriate without logging the mass! Let's see that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = K_absolute_magnitudes, masses\n",
    "slope, intercept, _, _, _ = st.linregress(x, y)\n",
    "\n",
    "xx = np.linspace(min(x), max(x), 100)\n",
    "plt.figure()\n",
    "plt.plot(x, y, \"k.\")\n",
    "plt.plot(xx, slope * xx + intercept, \"r-\")\n",
    "plt.xlabel(\"K-band absolute magnitude (mag)\")\n",
    "plt.ylabel(\"$M$ $(M_\\odot)$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test for such dependences, we can perform a **monotonicity test**. There are two widely used monotonicity checks through the *Spearman rank correlation coefficient* $r_s$ and the *Kendall rank correlation coefficient* $\\tau$ often referred as *Kendall's $\\tau$*. Their power relies on the fact that they are *non-parametric* and therefore they do not rely on an assumed model describing the data.\n",
    "\n",
    "For $r_s$ and $\\tau$:\n",
    "- 0: $x$ and $y$ are independent\n",
    "- 1: strictly increasing\n",
    "- -1: strictly decreasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = K_absolute_magnitudes, masses\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x, y, \"k.\")\n",
    "plt.show()\n",
    "# report correlation tests' p-values\n",
    "r, pvalue = st.pearsonr(x, y)\n",
    "print(\"PEARSON  : r = {:.3f}  |  p-value = {:.3g}\".format(r, pvalue))\n",
    "r, pvalue = st.spearmanr(x, y)\n",
    "print(\"SPEARMAN : r = {:.3f}  |  p-value = {:.3g}\".format(r, pvalue))\n",
    "r, pvalue = st.kendalltau(x, y)\n",
    "print(\"KENDALL  : t = {:.3f}  |  p-value = {:.3g}\".format(r, pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3><u>**In-class discussion: How do you interprete the small Pearson's $r$-value?**</u><font>\n",
    "\n",
    "_Discuss with your teammate, then report._\n",
    "\n",
    "<details>\n",
    "<summary><b>[Spoiler]</b></summary>\n",
    "<br>\n",
    "Despite the fact that the correlation is obvisouly non-linear, even the wrong model has to have a non-zero slope! Always remember your $H_0$ hypothesis! \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with a subset of the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_size = 5\n",
    "random_subset = np.random.choice(len(masses), size=subset_size)\n",
    "\n",
    "x, y = K_absolute_magnitudes[random_subset], masses[random_subset]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x, y, \"k.\")\n",
    "plt.show()\n",
    "# report correlation tests' p-values\n",
    "r, pvalue = st.pearsonr(x, y)\n",
    "print(\"PEARSON  : r = {:.3f}  |  p-value = {:.3g}\".format(r, pvalue))\n",
    "r, pvalue = st.spearmanr(x, y)\n",
    "print(\"SPEARMAN : r = {:.3f}  |  p-value = {:.3g}\".format(r, pvalue))\n",
    "r, pvalue = st.kendalltau(x, y)\n",
    "print(\"KENDALL  : t = {:.3f}  |  p-value = {:.3g}\".format(r, pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3><u>**In-class discussion: Run it many times. Do you notice differences in the Spearman and Kendall $p$-values?**</u><font>\n",
    "\n",
    "_Discuss with your teammate, then report._\n",
    "\n",
    "<details>\n",
    "<summary><b>[Spoiler]</b></summary>\n",
    "<br>\n",
    "All $p$-values vary, and sometimes close to our significance level of $5\\%$!\n",
    "\n",
    "Spearman's $p$-values vary by orders of magnitude!\n",
    "\n",
    "Kendall's $p$-values are never too extreme! In general, it is a more robust method!\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
