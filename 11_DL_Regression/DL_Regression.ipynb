{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6>**DL Regression**</font> </h6>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session we provide a short introduction to **Regression**, a topic which can be covered by both machine learning applications (such as those in [scikit-learn](https://scikit-learn.org/stable/index.html) we saw in clustering and classification session) and deep learning approaches. <br>\n",
    "The goals are:\n",
    "\n",
    "- to get an idea of how we **build and train** a deep learning model\n",
    "- explore some **basic concepts** to better understand their use and impact. \n",
    "\n",
    "In the example that will follow we are mainly going through these steps:\n",
    "\n",
    "    1. Load and Select Data\n",
    "    2. Define Model\n",
    "    3. Compile Model\n",
    "    4. Fit Model \n",
    "    5. Iterate steps 2-3-4 (by adjusting various parameters or the model architecture)\n",
    "    6. Evaluate Model\n",
    "    7. Make Predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is regression ?\n",
    "\n",
    "    Modeling problems where the output is a continuous numeric value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression and least squares\n",
    "\n",
    "A linear regression model will try to predict the single value of the dependent variable $y$ given the independent variable $x$, with the most generic form being: \n",
    "\n",
    "$$y = f (x | β), $$\n",
    "\n",
    "where $x$ corresponds to the input variable(s) and $β$ is an array of parameters.\n",
    "\n",
    "The simplest linear model we can think of is a line:\n",
    "\n",
    "$$y = β_0 + β_1 x $$\n",
    "\n",
    "where $β_0$ and $β_1$ have the usual meaning of intercept and slope of a line. \n",
    "\n",
    "Generalizing a bit, for an input vector $x^T = (x_1, x_2, ..., x_N)$,  where $N$ is the total number of observations (or samples), the linear model to predict the real-valued output $y$ is:\n",
    "\n",
    "$$ f(x) = β_0 + \\sum_{i=1}^{N} x_i β_i. $$\n",
    "\n",
    "To find these parameters we use the Ordinary Least Squares approach, i.e. we try to **minimize** the residual sum of the squares between the observations and the predictions by the model (i.e. the **loss or cost** function):\n",
    "\n",
    "$$ RSS(β) = \\sum_{i=1}^{N} (y_i - f(x_i))^2 =  \\sum_{i=1}^{N} (y_i - β_0 - x_i β_i)^2 .$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The more general linear regression\n",
    "\n",
    "Linear regression refers to modeling functions that are linear with respect to the parameters (coefficients) and not with respect to the variables! For example, the function:\n",
    "\n",
    "$$f (x|β) = \\sum_{i=1}^N β_i g_i(x) = β_1 g_1(x) + β_2 g_2(x)~+~...~+~β_N g_N(x) $$\n",
    "\n",
    "describes a linear problem as long as the sub-functions $g_i(x)$ do not depend on any of the parameters $β_i$. This is not the most generic formulation of the linear regression but we are going to use this form in the following applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On metrics ... or how well can we do\n",
    "\n",
    "> _Accuracy is a measure for classification not regression_<br>\n",
    "> _We cannot calculate accuracy for a regression model_\n",
    ">\n",
    ">  _by Jason Brownlee [Regression Metrics for Machine Learning](https://machinelearningmastery.com/regression-metrics-for-machine-learning/)_\n",
    "\n",
    "In regression we are dealing with continuous values. Therefore, it is actually impossible to predict the exact same values. The idea is to get an estimate of how close the predictions are to the expected values.\n",
    "\n",
    "We are going to refer only a few of the available metrics in [sklearn](https://machinelearningmastery.com/regression-metrics-for-machine-learning/). In the following $y$ refers to the dependent values while $\\hat{y}$ to the predicted values.\n",
    "\n",
    "**--> Mean Squared Error (MSE)**\n",
    "\n",
    "$$ MSE = \\frac{1}{N}\\sum_{i=1}^{N} (y_i - \\hat{y_i})^2 $$  \n",
    "\n",
    "It is actually the cost function of the Ordinary Least Squares (check $RSS(β)$ above). The units returned in this case are squared. Best score is 0.\n",
    "\n",
    "**--> Root Mean Squared Error (RMSE)**\n",
    "\n",
    "$$ RMSE = \\sqrt{ \\frac{1}{N}\\sum_{i=1}^{N} (y_i - \\hat{y_i})^2 } $$  \n",
    "\n",
    "It returns the square root of MSE so that the units match the units of the target value (so better interpretation).  Best score is 0.\n",
    "\n",
    "**--> Mean Absolute Error (MAE)**\n",
    "\n",
    "$$ MAE = {1 \\over N}\\sum_i^N{|  y_i-\\hat{y_i} |}$$  \n",
    "\n",
    "It is less sensitive to large errors when compared to (R)MSE. The score is in units of the target value and the best \n",
    "\n",
    "> Comment: Although arithetically the best scores for (R)MSE and MAE is 0 this cannot be the case in real-life problems. Instead a baseline model has to be determined and calculate its score. Then, any model that can achieve a score better that the baselie model is accepted as a skilful model.  \n",
    "\n",
    "\n",
    "**--> R2 (coefficient of determination)**\n",
    "\n",
    "$$R^2 = 1 - {\\sum_{i=1}^N{(y_i-\\hat{y_i})^2} \\over \\sum_{i=1}^N{(y_i - \\bar{y})^2}}, $$ \n",
    "\n",
    "where $\\bar{y} = \\frac{1}{n}\\sum_{i=1}^N y_i$. \n",
    "\n",
    "It represents the proportion of variance (of y) that has been explained by the independent variables in the model. It provides an indication of goodness of fit and therefore a measure of how well unseen samples are likely to be predicted by the model, through the proportion of explained variance. Best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application 1: Estimate SFR\n",
    "\n",
    "We will use data derived from the Heraklion Extragalactic Catalogue (HECATE; [Kovlakas et al, 2021](https://ui.adsabs.harvard.edu/abs/2021MNRAS.506.1896K/abstract)) which is an all-sky galaxy catalogue, containing about 200k galaxies (up to z=0.047, D≲200Mpc), and it offers positions, sizes, distances, morphological classifications, star formation rates, stellar masses, metallicities, and nuclear activity classifications. \n",
    "\n",
    "In particular, we are going to use a dataset from the work of [Kouroumpatzakis et al. 2023](https://ui.adsabs.harvard.edu/abs/2023A%26A...673A..16K/abstract) where they estimate the Star Formation Rates (SFR) and stellar mass using model Spectral Enerny Distributions with a variaty of parameters (optical and IR photometry, color terms, and stellar populations). \n",
    "\n",
    "**TASK: build a regression model to predict SFR**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>**CHALLENGE**:</font> </h4>   <br> \n",
    "    \n",
    "They used MCMC and Random Forest, so your work is to build a DL model that will **outperform their results**!!! <br>\n",
    "\n",
    "**Can you ?**\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<center><img src=\"images/yoda_meme.jpg\"></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading packages and defining some functions\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import keras\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Input, BatchNormalization,Conv3D, MaxPooling3D, Dense, Add, Activation\n",
    "from keras import regularizers\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam, SGD, Adagrad, RMSprop\n",
    "from IPython.display import clear_output\n",
    "\n",
    "class PlotLosses(keras.callbacks.Callback):\n",
    "    # NOTE: the current version can print only the first metric from the list provided\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.losses2 = []\n",
    "        self.val_losses2 = []\n",
    "        \n",
    "        self.fig = plt.figure()\n",
    "        \n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.losses2.append(logs.get( test_metrics[0] ) )\n",
    "        self.val_losses2.append(logs.get( f'val_{test_metrics[0]}' ))\n",
    "#         print(test_metrics[0] , logs.get( test_metrics[0] ), logs.get( f'val_{test_metrics[0]}' ))\n",
    "#         print(self.losses2)\n",
    "\n",
    "        self.i += 1\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(self.x, self.losses2, label=\"Train\",linestyle='-')\n",
    "        plt.plot(self.x, self.val_losses2, label=\"Validate\",linestyle='--')\n",
    "#        plt.ylim(0,1)\n",
    "        plt.legend()\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(test_metrics[0])\n",
    "        \n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(self.x, self.losses, label=\"Train\",linestyle='-')\n",
    "        plt.plot(self.x, self.val_losses, label=\"Validate\",linestyle='--')\n",
    "\n",
    "        plt.legend()\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        plt.show();\n",
    "        \n",
    "plot_losses = PlotLosses()\n",
    "\n",
    "\n",
    "def sub_ploots(plots_cols, plots_array):\n",
    "        \"\"\" Automatic adjustment of subplots\n",
    "        Given the \n",
    "        plots_cols     : plots per row (set manually)\n",
    "        plots_array    : array from which the number of \n",
    "                         individual subplots is derived\n",
    "\n",
    "        the output is given as \n",
    "        plots_cols     : plots per row\n",
    "        plots_rows     : number of necessary rows to create\n",
    "        \"\"\"\n",
    "        plots_unique = len((list(set(plots_array))))\n",
    "        plots_rows = int(np.ceil(plots_unique/plots_cols))\n",
    "        \n",
    "        return plots_rows, plots_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and checking data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "# following this tutorial :https://learn.astropy.org/tutorials/FITS-tables.html\n",
    "\n",
    "data_fits = fits.open('data/CIGALE_SFR.fits', memmap=True)\n",
    "\n",
    "# printing some information \n",
    "data_fits.info()\n",
    "print('-----')\n",
    "print(data_fits[1].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the data table \n",
    "\n",
    "data_tab = Table(data_fits[1].data)\n",
    "data_tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting features\n",
    "\n",
    "In this part we can select which features we want to keep and use to train our model. Feel free to choose any number of feature - keep in mind though **NOT** to select `sfr` and `mstar` as these are needed for the output (i.e. are the values we want to predict).\n",
    "\n",
    "_HINT_: for the column names check above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_features = [ ... , ...  ]\n",
    "\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "\n",
    "rws, cls = sub_ploots(2, sel_features)  # for subplots\n",
    "for f in range(len(sel_features)):\n",
    "    f_name = sel_features[f]\n",
    "    ax = fig.add_subplot(rws, cls, f+1)\n",
    "    ax.set_title(f'Feature {f_name}')\n",
    "    ax.hist(data_tab[f_name], bins='auto', align='mid', density=True)\n",
    "    ax.set_xlabel('feature value')\n",
    "    ax.set_ylabel('number of objects')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the data table looks like ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tab[sel_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting table objects to numpy arrays\n",
    "\n",
    "values = data_tab[sel_features].as_array()\n",
    "values = values.view((float, len(values.dtype.names)))\n",
    "target = np.array(data_tab['sfr']).reshape(-1,1)\n",
    "\n",
    "print('The values for selected features:')\n",
    "print(values)\n",
    "print()\n",
    "print('The target quantity:')\n",
    "print(target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the sample and ... ?\n",
    "\n",
    "**TASK: what should you do before training the model?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split( ... , ... ,\n",
    "                        test_size= ... ) #, random_state=42) \n",
    "X_train, X_valid, y_train, y_valid = train_test_split( ... , ...,\n",
    "                        test_size= ... ) #, random_state=42) \n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = ... \n",
    "X_valid_scaled = ...\n",
    "X_test_scaled = ...\n",
    "\n",
    "print(f'> From {len(target)} sources:')\n",
    "print(f'   {len(X_train)} (train)')\n",
    "print(f'   {len(X_valid)} (validation)')\n",
    "print(f'   {len(X_test)} (test)') \n",
    "print('\\n> Statistics per feature:')\n",
    "print(f'Mean: {scaler.mean_}')\n",
    "print(f'Variance: {scaler.var_}')\n",
    "print()\n",
    "print(f' Target shape: {y_train.shape}') # print the shape of the output values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to build our model! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want you can add more output metrics!\n",
    "# but keep in mind that the plot_losses will use the first one.\n",
    "\n",
    "test_metrics = [ 'mean_squared_error'] #, 'mean_absolute_error', ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add( Dense( ... , input_shape=X_train_full.shape[1:], activation='relu') )\n",
    "\n",
    "#model.add( Dense( ... , activation='relu') )\n",
    "\n",
    "\n",
    "model.add( Dense( ... ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optzr = Adam(lr= ... ) \n",
    "model.compile(loss='mean_squared_error', optimizer=optzr, metrics = test_metrics)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally ... train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time() \n",
    "\n",
    "history=model.fit( ... ,...  \n",
    "                    batch_size= ..., \n",
    "                    epochs= ...,\n",
    "                    validation_data=[ X_valid_scaled, y_valid],\n",
    "                    callbacks=[plot_losses],shuffle=True)\n",
    "\n",
    "# to print history contents\n",
    "# history.history\n",
    "elapsed_time = time.time() - start_time\n",
    "time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ... and the moment of truth - evaluation\n",
    "\n",
    "_HINT_: remember at which set we evaluate our model to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = model.evaluate( ... , ... )\n",
    "print(f\"Loss value: {evaluation[0]:.2f}\")  \n",
    "for m in range(len(test_metrics)):\n",
    "    print(f\"{test_metrics[m]}: {evaluation[m+1]:0.2f}\")  \n",
    "    \n",
    "y_pred = model.predict( ... )    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the predicitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "r2 = r2_score( ... , ...)\n",
    "\n",
    "min_ax, max_ax = np.min(y_test), np.max(y_test)\n",
    "    \n",
    "plt.plot(y_test, y_pred, '.', alpha=0.4)\n",
    "plt.title( f'R2 = {r2:0.2f}', fontsize=20)\n",
    "plt.xlabel('true', fontsize=16)\n",
    "plt.ylabel('prediction', fontsize=16)\n",
    "plt.xlim([min_ax, max_ax])\n",
    "\n",
    "# 1-to-1 line:\n",
    "xx = np.linspace(min_ax, max_ax, 100)\n",
    "plt.plot(xx, xx, c=\"grey\", linestyle='--')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing with paper results! Is it better ???\n",
    "\n",
    "Comparing your results with Fig 3 by [Kouroumpatzakis et al. (2023)](https://ui.adsabs.harvard.edu/abs/2023A%26A...673A..16K/abstract), where the ratio of the predictions over true SFR values are plotted with true SFR values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting data to 2d and sorting \n",
    "arr = np.concatenate( (y_test, y_pred), axis=1 )\n",
    "res = np.sort(arr, axis = 0)       \n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "objs = np.arange(len(res))\n",
    "\n",
    "plt.plot( np.log(res[:,0]), np.log( res[:,0]/res[:,1]), '-g')\n",
    "plt.xlabel('log SFR true', fontsize=16)\n",
    "plt.ylabel('log (SFR pred / SFR true)', fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<center><img src=\"images/Kouroumpatzakis2023-Fig3b.png\"> \n",
    "Figure 5.1. Figure 3 from   <a href=\"https://ui.adsabs.harvard.edu/abs/2023A%26A...673A..16K/abstract\" target=\"_blank\" rel=\"noopener noreferrer\">Kouroumpatzakis et al. (2023)</a> presenting the omparison between the true SFR as given by the CIGALE output (data used), and the best-fit models of MCMC, and the Random Forest.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Question**: So... did you manage to do better ?_\n",
    "\n",
    "_HINT_: the resulted range should be smaller...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application 2: Estimate SFR and stellar mass\n",
    "\n",
    "In this case we want to use all/part of the available features to estimate both the SFR (`sfr`) **and** the stellar mass (`mstar`). \n",
    "\n",
    "For this we need to adjust the number of output nodes and the shape of the data. \n",
    "\n",
    "**TASK 1: adjust the model to train and predict both values**\n",
    "\n",
    "**TASK 2: use a custom loss function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_fits[1].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select data \n",
    "\n",
    "sel_features = [ ... ... ]\n",
    "pre_features = [ ... ...]\n",
    "\n",
    "values = data_tab[sel_features].as_array()\n",
    "values = values.view((float, len(values.dtype.names)))\n",
    "\n",
    "target = data_tab[pre_features].as_array()\n",
    "target = target.view((float, len(target.dtype.names)))\n",
    "\n",
    "\n",
    "print('The values for selected features:')\n",
    "print(values)\n",
    "print()\n",
    "print('The target quantity:')\n",
    "print(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split( ... ,... ,\n",
    "                        test_size= ... ) #, random_state=42) \n",
    "X_train, X_valid, y_train, y_valid = train_test_split(... ,... ,\n",
    "                        test_size= ... ) #, random_state=42) \n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = ...\n",
    "X_valid_scaled = ...\n",
    "X_test_scaled = ...\n",
    "\n",
    "print(f'> From {len(target)} sources:')\n",
    "print(f'   {len(X_train)} (train)')\n",
    "print(f'   {len(X_valid)} (validation)')\n",
    "print(f'   {len(X_test)} (test)') \n",
    "print('\\n> Statistics per feature:')\n",
    "print(f'Mean: {scaler.mean_}')\n",
    "print(f'Variance: {scaler.var_}')\n",
    "print()\n",
    "print(f' Target shape: {y_train.shape}') # print the shape of the output values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below defines an example of loss function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def custom_mse(y_true, y_pred):\n",
    " \n",
    "    # calculating squared difference between target and predicted values \n",
    "    loss = K.square(y_pred - y_true)  # (batch_size, 2)\n",
    "    print(loss)\n",
    "    \n",
    "    # multiplying the values with weights along batch dimension\n",
    "    loss = loss * [0.5, 0.5]          # (batch_size, 2)\n",
    "    print(loss)  \n",
    "    # summing both loss values along batch dimension \n",
    "    loss = K.sum(loss, axis=1)        # (batch_size,)\n",
    "\n",
    "    return loss\n",
    "\n",
    "# if ypu want to add more output metrics\n",
    "# test_metrics = [ 'mean_absolute_error', 'mean_squared_error']\n",
    "test_metrics = [ 'mean_squared_error'] #, 'mean_absolute_error', ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add( Dense( ... , input_shape=X_train_full.shape[1:], activation='relu') )\n",
    "\n",
    "#model.add( Dense( ... , activation='relu') )\n",
    "\n",
    "\n",
    "model.add( Dense( ... ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optzr =  Adam(lr= ... )\n",
    "model.compile(loss='mean_squared_error', optimizer=optzr, metrics = test_metrics)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time() \n",
    "\n",
    "history=model.fit( ... , ... \n",
    "                    batch_size= ..., \n",
    "                    epochs= ...,\n",
    "                    validation_data=[ ... , ...],\n",
    "                    callbacks=[plot_losses],shuffle=True)\n",
    "\n",
    "# to print history contents\n",
    "# history.history\n",
    "elapsed_time = time.time() - start_time\n",
    "time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = model.evaluate( ... ,...)\n",
    "print(f\"Loss value: {evaluation[0]:.2f}\")  \n",
    "for m in range(len(test_metrics)):\n",
    "    print(f\"{test_metrics[m]}: {evaluation[m+1]:0.2f}\")  \n",
    "\n",
    "print('------')\n",
    "\n",
    "y_pred = model.predict( ... ) \n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(12,6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "  \n",
    "    r2 = r2_score( y_test[:,i] , y_pred[:,i])\n",
    "    \n",
    "    min_ax, max_ax = np.min(y_test[:,i]), np.max(y_test[:,i])\n",
    "\n",
    "    ax.plot(y_test[:,i], y_pred[:,i], '.', alpha=0.4)\n",
    "    ax.set_title( f'R2 = {r2:0.2f} for {pre_features[i]}', fontsize=20)\n",
    "    ax.set_xlabel('true', fontsize=16)\n",
    "    ax.set_ylabel('prediction', fontsize=16)\n",
    "    ax.set_xlim([min_ax, max_ax])\n",
    "\n",
    "    min_ax, max_ax = np.min(y_test[:,i]), np.max(y_test[:,i])\n",
    "    # 1-to-1 line:\n",
    "    xx = np.linspace(min_ax, max_ax, 100)\n",
    "    ax.plot(xx, xx, c=\"grey\", linestyle='--')\n",
    "    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "409.6px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
