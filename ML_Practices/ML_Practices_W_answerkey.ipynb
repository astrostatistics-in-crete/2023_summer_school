{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6>**Machine Learning Practises - Workshop**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level 2 $-$ Hyperparameter tuning\n",
    "\n",
    "\n",
    "> _How do I select the best hyperparameters, and assess the performance?_\n",
    "\n",
    "\n",
    "<table><tr>\n",
    "    <td width=200>\n",
    "        <img src=\"images/Goku_SS1.jpg\">\n",
    "    </td>\n",
    "</tr></table>\n",
    "\n",
    "**Hyperparameter tuning** == **select** the best hyperparameters of a model.\n",
    "\n",
    "What \"**best**\" means?  As usual, the ones which return the best metric of performance on some test set.\n",
    "\n",
    "For example, let's consider the Random Forests **classifier** (RF**C**)\n",
    "\n",
    "&emsp; $\\rightarrow$  <code>sklearn</code> implementation of RFC has 10 tunable hyperparameters (_plus a few more related to the computational execution_):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(self, n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n"
     ]
    }
   ],
   "source": [
    "# Let's visualize the RF hyperparameters:\n",
    "import inspect\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "models = [RandomForestClassifier]\n",
    "\n",
    "for m in models:\n",
    "    hyperparams = inspect.signature(m.__init__)\n",
    "    print(hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV for hyperparameter tuning\n",
    "\n",
    "As anticipated in the previous notebook (`ML_Practices_S.ipynb`) $\\rightarrow$ <u>we can use CV</u> to select the best hyperpars.\n",
    "\n",
    "Let's assume we consider 3 different **hyperparamers sets** (i.e., **configurations**), hence defining 3 estimators:\n",
    "- _Estimator A_\n",
    "- _Estimator B_\n",
    "- _Estimator C_\n",
    "\n",
    "<table><tr>\n",
    "    <td width=800>\n",
    "        <img src=\"images/CV_k4_hyperpar_estimator.png\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 1.1.  Cross Validation protocol used as hyperparameter selector.<br>\n",
    "            Every \"<i>Estimator</i>\" is setup using a different hyerparameter set.\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>\n",
    "\n",
    "$\\rightarrow$ The <u>selected</u> **hyperparameter set** (**configuration**) is the one yielding the **best average performance**.\n",
    "\n",
    "<font size=3><u>**True performance**</u><font>\n",
    "\n",
    "> The true performance of the selected model is <u>not</u> the one returned by the CV.\n",
    "\n",
    "That will be an **overestimate**.\n",
    "\n",
    "_Why?_ $\\rightarrow$ Because we would look at the validation folds both to select the model <u>and</u> to asess it!\n",
    "\n",
    "> Violation of Golden Rule! $\\rightarrow$ <u>The test set must come from the future!</u>\n",
    "\n",
    "Imagine trying 1 million parameter sets: you will always find a good model which adapts to the data just by chance.\n",
    "    \n",
    "_See discussion in [2022 Summer School for Astrostatistics in Crete - ML Practices Workshop](https://github.com/astrostatistics-in-crete/2022_summer_school/blob/main/ML_Practices/ML_Practices_W_answerkey.ipynb) for a mathematical proof._\n",
    "    \n",
    "- - -\n",
    "\n",
    "<u>Solution</u> $\\rightarrow$ We need to **hold-out** a test set:\n",
    "    \n",
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/Hyperpar_Tuning.png\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 1.2.  Correct protocol for **hyperparameter tuning + testing**.<br>\n",
    "            (From <a href=\"https://scikit-learn.org/stable/modules/cross_validation.html\">this sklearn page</a>)\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3><u>**Example: tuning Random Forests**</u><font>\n",
    "\n",
    "E.g., consider these <code>sklearn.ensemble</code> Random Forests parameters:\n",
    "- <code>n_estimators</code> (_the number of trees_)\n",
    "- <code>max_depth</code> (_the _max ramification of the trees_)\n",
    "- <code>max_features</code> (_the max number of features to consider in each split_)\n",
    "  \n",
    "If we want, e.g., to try a 5-fold CV on this **parameter grid**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators':  [10, 50],\n",
    "     'max_depth':    [2, 8],\n",
    "     'max_features': [3, 5],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$\\rightarrow$ How many models will we fit?\n",
    "    \n",
    "<details>\n",
    "<summary><b>[Spoiler]</b></summary>\n",
    "That is 2$^3$ = 8 configurations, on a 5-fold CV $\\rightarrow$ we will train 8 x 5 + 1 = 41 models.\n",
    "\n",
    "_NOTE: The final \"+1\" is because the selected configuration is **retrained on all data**._\n",
    "</details>\n",
    "\n",
    "- - -\n",
    "    \n",
    "Let's see it action with the usual Kaggle's [Stellar Classification Dataset - SDSS17](https://www.kaggle.com/datasets/fedesoriano/stellar-classification-dataset-sdss17).<br>\n",
    "\n",
    "We will perform the full grid search using ``sklearn.model_selection.GridSearchCV``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>i</th>\n",
       "      <th>z</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23441</th>\n",
       "      <td>22.30567</td>\n",
       "      <td>21.43649</td>\n",
       "      <td>19.75798</td>\n",
       "      <td>18.96968</td>\n",
       "      <td>18.53585</td>\n",
       "      <td>GALAXY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90125</th>\n",
       "      <td>17.91316</td>\n",
       "      <td>16.73492</td>\n",
       "      <td>16.57163</td>\n",
       "      <td>16.53089</td>\n",
       "      <td>16.53141</td>\n",
       "      <td>STAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57892</th>\n",
       "      <td>23.00886</td>\n",
       "      <td>22.49020</td>\n",
       "      <td>20.71650</td>\n",
       "      <td>19.74547</td>\n",
       "      <td>19.15290</td>\n",
       "      <td>GALAXY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7228</th>\n",
       "      <td>19.80938</td>\n",
       "      <td>17.89119</td>\n",
       "      <td>16.83623</td>\n",
       "      <td>16.35335</td>\n",
       "      <td>15.95283</td>\n",
       "      <td>GALAXY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99545</th>\n",
       "      <td>24.32647</td>\n",
       "      <td>23.16088</td>\n",
       "      <td>21.35538</td>\n",
       "      <td>20.36712</td>\n",
       "      <td>19.68588</td>\n",
       "      <td>GALAXY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              u         g         r         i         z   class\n",
       "23441  22.30567  21.43649  19.75798  18.96968  18.53585  GALAXY\n",
       "90125  17.91316  16.73492  16.57163  16.53089  16.53141    STAR\n",
       "57892  23.00886  22.49020  20.71650  19.74547  19.15290  GALAXY\n",
       "7228   19.80938  17.89119  16.83623  16.35335  15.95283  GALAXY\n",
       "99545  24.32647  23.16088  21.35538  20.36712  19.68588  GALAXY"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features in X: 5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_star = pd.read_csv(\"data/star_classification.csv\")\n",
    "df_star = df_star.sample(n=100, random_state=12)\n",
    "# keeping only a few objects to make the problem more challenging\n",
    "\n",
    "features = ['u', 'g', 'r', 'i', 'z']\n",
    "df_star_ = df_star[features+['class']]\n",
    "display(df_star_.head(5))\n",
    "\n",
    "X = df_star_[features].values\n",
    "y = df_star_['class'].values\n",
    "\n",
    "print('Number of features in X:', np.shape(X)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV 1/5] END max_depth=2, max_features=3, n_estimators=10;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END max_depth=2, max_features=3, n_estimators=10;, score=0.571 total time=   0.0s\n",
      "[CV 3/5] END max_depth=2, max_features=3, n_estimators=10;, score=0.643 total time=   0.0s\n",
      "[CV 4/5] END max_depth=2, max_features=3, n_estimators=10;, score=0.714 total time=   0.0s\n",
      "[CV 5/5] END max_depth=2, max_features=3, n_estimators=10;, score=0.643 total time=   0.0s\n",
      "[CV 1/5] END max_depth=2, max_features=3, n_estimators=50;, score=0.786 total time=   0.1s\n",
      "[CV 2/5] END max_depth=2, max_features=3, n_estimators=50;, score=0.786 total time=   0.1s\n",
      "[CV 3/5] END max_depth=2, max_features=3, n_estimators=50;, score=0.714 total time=   0.1s\n",
      "[CV 4/5] END max_depth=2, max_features=3, n_estimators=50;, score=0.786 total time=   0.1s\n",
      "[CV 5/5] END max_depth=2, max_features=3, n_estimators=50;, score=0.643 total time=   0.1s\n",
      "[CV 1/5] END max_depth=2, max_features=5, n_estimators=10;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END max_depth=2, max_features=5, n_estimators=10;, score=0.571 total time=   0.0s\n",
      "[CV 3/5] END max_depth=2, max_features=5, n_estimators=10;, score=0.786 total time=   0.0s\n",
      "[CV 4/5] END max_depth=2, max_features=5, n_estimators=10;, score=0.643 total time=   0.0s\n",
      "[CV 5/5] END max_depth=2, max_features=5, n_estimators=10;, score=0.643 total time=   0.0s\n",
      "[CV 1/5] END max_depth=2, max_features=5, n_estimators=50;, score=0.786 total time=   0.1s\n",
      "[CV 2/5] END max_depth=2, max_features=5, n_estimators=50;, score=0.786 total time=   0.1s\n",
      "[CV 3/5] END max_depth=2, max_features=5, n_estimators=50;, score=0.643 total time=   0.1s\n",
      "[CV 4/5] END max_depth=2, max_features=5, n_estimators=50;, score=0.714 total time=   0.1s\n",
      "[CV 5/5] END max_depth=2, max_features=5, n_estimators=50;, score=0.643 total time=   0.1s\n",
      "[CV 1/5] END max_depth=8, max_features=3, n_estimators=10;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END max_depth=8, max_features=3, n_estimators=10;, score=0.786 total time=   0.0s\n",
      "[CV 3/5] END max_depth=8, max_features=3, n_estimators=10;, score=0.929 total time=   0.0s\n",
      "[CV 4/5] END max_depth=8, max_features=3, n_estimators=10;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END max_depth=8, max_features=3, n_estimators=10;, score=0.643 total time=   0.0s\n",
      "[CV 1/5] END max_depth=8, max_features=3, n_estimators=50;, score=0.714 total time=   0.1s\n",
      "[CV 2/5] END max_depth=8, max_features=3, n_estimators=50;, score=0.857 total time=   0.1s\n",
      "[CV 3/5] END max_depth=8, max_features=3, n_estimators=50;, score=0.786 total time=   0.1s\n",
      "[CV 4/5] END max_depth=8, max_features=3, n_estimators=50;, score=0.714 total time=   0.1s\n",
      "[CV 5/5] END max_depth=8, max_features=3, n_estimators=50;, score=0.571 total time=   0.1s\n",
      "[CV 1/5] END max_depth=8, max_features=5, n_estimators=10;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END max_depth=8, max_features=5, n_estimators=10;, score=0.786 total time=   0.0s\n",
      "[CV 3/5] END max_depth=8, max_features=5, n_estimators=10;, score=0.714 total time=   0.0s\n",
      "[CV 4/5] END max_depth=8, max_features=5, n_estimators=10;, score=0.714 total time=   0.0s\n",
      "[CV 5/5] END max_depth=8, max_features=5, n_estimators=10;, score=0.643 total time=   0.0s\n",
      "[CV 1/5] END max_depth=8, max_features=5, n_estimators=50;, score=0.786 total time=   0.1s\n",
      "[CV 2/5] END max_depth=8, max_features=5, n_estimators=50;, score=0.857 total time=   0.1s\n",
      "[CV 3/5] END max_depth=8, max_features=5, n_estimators=50;, score=0.714 total time=   0.1s\n",
      "[CV 4/5] END max_depth=8, max_features=5, n_estimators=50;, score=0.714 total time=   0.1s\n",
      "[CV 5/5] END max_depth=8, max_features=5, n_estimators=50;, score=0.571 total time=   0.1s\n",
      "\n",
      "Best configuration:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {color: black;background-color: white;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=8, max_features=3, n_estimators=10,\n",
       "                       random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" checked><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=8, max_features=3, n_estimators=10,\n",
       "                       random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=8, max_features=3, n_estimators=10,\n",
       "                       random_state=42)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy of best configuration on hold-out test set: 0.77\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Defining the search --------------------------------------------------------\n",
    "#\n",
    "# Using:\n",
    "#   - `GridSearchCV` as the search strategy\n",
    "#   - `param_grid` as the search space  \n",
    "#   - `scoring` as the performance metric to select the best configuration\n",
    "#\n",
    "search = GridSearchCV(clf, param_grid, scoring='accuracy', refit=True, verbose=3)\n",
    "#\n",
    "# NOTE: Setting `refit`=True will refit the selected configuration on all CV data\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "# Fitting the grid of estimators ---------------------------------------------\n",
    "#\n",
    "# Internally, sklearn does the whold job:\n",
    "#   - iterates over the CV loops\n",
    "#   - splits the folds\n",
    "#   - instantiates the estimators with the iteration's hyperparameter set\n",
    "#   - calls the <estimator>.fit() method\n",
    "#   - applies the scoring function\n",
    "#\n",
    "search.fit(X_train, y_train)\n",
    "#\n",
    "# IMPORTANT: Notice how we run the CV on the \"train\" data alone\n",
    "#            (these will be internally split in the CV loops).\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "print('\\nBest configuration:')\n",
    "display(search.best_estimator_)\n",
    "\n",
    "# Predicting on held-out test:\n",
    "yhat_test = search.best_estimator_.predict(X_test)\n",
    "# NOTE: `search.best_estimator_` is just an other `sklearn` RandomForest object.\n",
    "#       Hence, it has its own `fit()`, `predict()`, etc. methods.\n",
    "\n",
    "# Evaluating score:\n",
    "score = accuracy_score(y_test, yhat_test)\n",
    "\n",
    "print('\\nAccuracy of best configuration on held-out test set: %.2f' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make it more complicated: let's add some preprocessing, which become part of the pipilene.\n",
    "\n",
    "So now the model is not just the classifier, but:\n",
    "\n",
    "> **Model** = **preprocessing + classifier**.\n",
    "\n",
    "Recall that in general, a model contains _all_ the steps that go from the **input** to the **output** and that must be trained concurrently (**golden rule**):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/Model.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 1.A.  A generic model template, containing several other steps apart from the Classifier.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "    <td width=256>\n",
    "        <img src=\"images/I_Am_The_Model_Now.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 1.B.  Don't mess with the model.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our preprocessing will be a **Principal Component** dimensionality reduction.\n",
    "\n",
    "This also has an hyperparameter: the number of dimensions ($n_{dim}$) we want to reduce to.\n",
    "\n",
    "How do we account for this?  We can do it simply by creating a **hyperparameter array**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/Model_Hyperparameters.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 2.  Hyperparameters for the generic model template shown above.\n",
    "            Individual steps might be switched on/off by creating a proxy\n",
    "            hyperparameter\n",
    "            that can take a value of 1 if the specific step is used, or 0 if not.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTATION WARNING:\n",
    "\n",
    "We can see these names used interchangeably, but their $un$-ambiguous definitions would be:\n",
    "\n",
    "> - **configuration**: a specific set of hyperparameters (_defines which algorithms we pick and their tuning_)\n",
    "> - **model**: a fitted configuration (_the same configuration trained on 2 different sets give birth to 2 different models_)\n",
    "> - **learning method**: the procedure of finding the best-fitting model (_the \"master\" model_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "\n",
    "We can assemble the Model using [<code>sklearn.pipeline</code>](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('PCA', PCA()), ('RFC', RandomForestClassifier())])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model = Pipeline([('PCA', PCA()), ('RFC', RandomForestClassifier())])\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data\n",
    "\n",
    "Let's generate some synthetic data to play with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|     Data shape     |\n",
      "+-----------+--------+\n",
      "|     X     |   y    |\n",
      "+-----------+--------+\n",
      "| (300, 10) | (300,) |\n",
      "+-----------+--------+\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from prettytable import PrettyTable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X, y = make_classification(n_samples=300, n_features=10, n_informative=7,\n",
    "                           n_redundant=0, n_repeated=0, n_classes=2,\n",
    "                           n_clusters_per_class=1, weights=None, flip_y=0.01,\n",
    "                           class_sep=0.5, hypercube=True, shift=0.0, scale=1.0,\n",
    "                           shuffle=True, random_state=42)\n",
    "\n",
    "table = PrettyTable()\n",
    "table.title = str('Data shape')\n",
    "table.field_names = ['X', 'y']\n",
    "table.add_row([np.shape(X), np.shape(y)])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+\n",
      "|         Data shape         |\n",
      "+-------+-----------+--------+\n",
      "|  set  |     X     |   y    |\n",
      "+-------+-----------+--------+\n",
      "| train | (210, 10) | (210,) |\n",
      "|  test |  (90, 10) | (90,)  |\n",
      "+-------+-----------+--------+\n"
     ]
    }
   ],
   "source": [
    "# Splitting the sample for training and test:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "table = PrettyTable()\n",
    "table.title = str('Data shape')\n",
    "table.field_names = ['set', 'X', 'y']\n",
    "table.add_row(['train', np.shape(X_train), np.shape(y_train)])\n",
    "table.add_row(['test',  np.shape(X_test),  np.shape(y_test)])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting and tuning the hyperparameters\n",
    "\n",
    "We will use **Cross Validation with Tuning (CVT)** but reserve a **hold-out** test set for double-checking:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/CV_holdout_split.png\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 3. Hold-out split.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will evaluate the average performance of **each configuration** over the folds.\n",
    "\n",
    "- The **best** configuration will be the one yielding the best average performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=1000>\n",
    "        <img src=\"images/CV_k4_hyperpar.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 4. Cross Validation protocol, which will be applied to each configuration.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: In practice, we proceed it in this way:\n",
    "\n",
    "1. We perform the first split into $k$ folds\n",
    "2. We fit all models on the training folds, and record their performance on the validation fold\n",
    "3. We repeat for the next split, until all possible splits are performed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter search strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But which strategy shall we choose to explore the hyperparameter space? <br>\n",
    "I.e., which parameter configurations shall we check?\n",
    "\n",
    "    The hyperparameter space is potentially infinite.\n",
    "\n",
    "One simple approach (and surprisingly effective!) is the:\n",
    "> **Random Search**: Try randomly drawn parameter configurations until a pre-determined time limit\n",
    "\n",
    "Here we will try the [<code>sklearn GridSearchCV</code>](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html):\n",
    "\n",
    "> **Grid Search**: Set a range for the parameters and exhaustively search within it\n",
    "\n",
    "First, we define the parameter limits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PCA__n_components': [2, 3, 5, 8],\n",
       " 'RFC__n_estimators': [10, 20, 50, 100],\n",
       " 'RFC__max_depth': array([2, 4, 6, 8])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "param_grid = {\n",
    "    \"PCA__n_components\": [2, 3, 5, 8],\n",
    "    \"RFC__n_estimators\": [10, 20, 50, 100],\n",
    "    \"RFC__max_depth\": np.arange(2, 10, 2),\n",
    "}\n",
    "'''\n",
    "The syntax of this dictionary is:\n",
    "    <label_as_you_defined_in_pipe>__<parameter_name_as_in_sklearn_documentation>\n",
    "Type, e.g.:\n",
    "    RandomForestClassifier?\n",
    "to visualize all the possible parameters    \n",
    "''';\n",
    "\n",
    "display(param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created a grid over 3 hyperparameters (and let the rest to keep the default values), and sampled only 4 values for each of them.\n",
    "\n",
    "Keep in mind that the Grid Search is extremely time consuming $\\rightarrow$ How many models we need to train?\n",
    "\n",
    "NOTE: See the [<code>sklearn</code> tutorial](https://scikit-learn.org/stable/tutorial/statistical_inference/putting_together.html) on how to combine a Grid Search with a pipeline model.\n",
    "\n",
    "\n",
    "Let's now implement the **search strategy**, including the Cross Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy',\n",
    "                      n_jobs=-1, refit=True, return_train_score=True)\n",
    "'''\n",
    "Read this as:\n",
    "    \"Perform a Grid Search on Model <model> creating the configurations using\n",
    "    the parameter grid <param_grid>, and Cross Validation with 5 folds.\n",
    "    Use accuracy to evaluate the configurations.\n",
    "    \n",
    "refit = True\n",
    "    Will refit the best found model on the whole dataset, which is the actual\n",
    "    model we shall use for prediction on unseen data!\n",
    "    By doing that, after the training is complete, we can just predict by \n",
    "    using the standard sklearn syntax:\n",
    "    \n",
    "        yhat = search.best_estimator_predict(X)\n",
    "''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the Model\n",
    "\n",
    "This uses the usual <code>sklearn</code> syntax, but on the <code>search</code> object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration:\n",
      "{'PCA__n_components': 8, 'RFC__max_depth': 4, 'RFC__n_estimators': 100}\n",
      "\n",
      "Best configuration: mean CV score = 0.867\n",
      "\n",
      "CPU times: user 532 ms, sys: 74.6 ms, total: 606 ms\n",
      "Wall time: 5.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "search.fit(X_train, y_train)\n",
    "# NOTE: We pass the whole dataset, the CV fold splitting is done internally!\n",
    "\n",
    "print(\"Best configuration:\")\n",
    "print(search.best_params_)\n",
    "\n",
    "print(\"\\nBest configuration: mean CV score = %0.3f\\n\" % search.best_score_)\n",
    "# NOTE: The best configuration is the one with the best _mean_ score across\n",
    "#       folds, not the one with the absolute best score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot twist: the assessment method is _wrong_!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# > Check distribution of the scores\n",
    "\n",
    "# GridSearch stores the test scores across the folds under the\n",
    "# \"mean_test_score\" entry of the trained <search.cv_results_> dictionary.\n",
    "# They are indexed by configuration, e.g., entry 0 refers to configuration 0\n",
    "\n",
    "mean_test_scores = search.cv_results_['mean_test_score']\n",
    "# mean scores across test sets (== validation sets, in the case of CV), one per model\n",
    "\n",
    "best_score_folds = [search.cv_results_['split'+str(i)+'_test_score'][search.best_index_] for i in range(search.n_splits_)]\n",
    "# all scores of best model, one per fold\n",
    "\n",
    "# Let's plot the histogram of the scores obtained by each model:\n",
    "# NOTE: The score of a model is itself averaged over the k validation folds\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.title('Distribution of scores averaged over test folds')\n",
    "plt.hist(mean_test_scores, color='steelblue', label='All models scores')\n",
    "plt.axvline(x=np.mean(mean_test_scores), lw=5, ls='--', c='tomato', label='Mean score across models')\n",
    "\n",
    "cmap = plt.cm.get_cmap('tab10_r', 10)\n",
    "for i, best_score_fold in enumerate(best_score_folds):\n",
    "    plt.axvline(x=best_score_fold, ymin=0, ymax=0.2, lw=3, ls='-', c=cmap(i), \\\n",
    "                label='Score of best model on fold %s (%.2f%%)' % (str(i), best_score_fold))\n",
    "plt.axvline(x=search.best_score_, lw=5, ls='-', c='black', \\\n",
    "            label='Score of re-fit best model')\n",
    "\n",
    "plt.xlabel('score value')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WARNING: In <code>GridSearchCV</code> we set <code>refit=True</code>.\n",
    "\n",
    "&emsp; Hence, the \"**best model**\" is the best configuration re-fit on the whole dataset, but its \"**best score**\" is _still_ the average of the cross-validated scores.<br>\n",
    "&emsp; _(See discussion [here](https://stackoverflow.com/questions/50232599/interpreting-sklearns-gridsearchcv-best-score))_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>What is the problem?</u>\n",
    "\n",
    "The best score is the performance of a model selected using that very performance!\n",
    "\n",
    "> We looked at the future (validation folds) to select the model $\\rightarrow$ violation of **Golden Rule**!\n",
    "\n",
    "a.k.a. **Winner's curse**: we cannot be sure that the best model is indeed the best for unseen data.\n",
    "\n",
    "<u>Demonstration</u>\n",
    "\n",
    "Let's say we test $i$ = {0, 1, .. $n$} models, each returning an average score $\\hat{S_{i}}$ from the CV.\n",
    "\n",
    "- The **CVT method selects** the model returning the **best average score**: $max$($\\hat{S_{0}}$ .. $\\hat{S_{n}}$).<br>\n",
    "  _$\\rightarrow$ Let's say that the best model is found at index $i = k$_.<br><br>\n",
    "\n",
    "- If we repeated the CV experiment **many times**, with different data, which would be the **expectation on the best score**?\n",
    "\n",
    "$$ \\mathbb{E}(max(\\hat{S_{0}} .. \\hat{S_{n}})) $$\n",
    "\n",
    "- From Jensens' inequality we know that, for every **$i$**\\:\n",
    "\n",
    "$$ \\mathbb{E}(max(\\hat{S_{0}} .. \\hat{S_{n}})) \\ge \\mathbb{E}(\\hat{S_{i}}) $$ \n",
    "\n",
    "- Let's focus on our best model, i.e. $i = k$:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathbb{E}(max(\\hat{S_{0}} .. \\hat{S_{n}})) \\ge \\mathbb{E}(\\hat{S_{k}})\n",
    "\\label{equation:expectation} \\tag{1}\n",
    "\\end{equation*}\n",
    "\n",
    "Therefore our selection method, i.e. $max$($\\hat{S_{0}}$ .. $\\hat{S_{n}}$), is expected to return a **larger** score than the _true_ expected score for that model, i.e. $\\mathbb{E}(\\hat{S_{k}})$.\n",
    "$\\blacksquare$\n",
    "\n",
    "_(See discussion [here](https://stats.stackexchange.com/questions/480984/why-cross-validation-gives-biased-estimates-of-error))_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=128>\n",
    "        <img src=\"images/Deal_With_It.png\">\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on test set: 0.86%\n"
     ]
    }
   ],
   "source": [
    "# And in fact, when we apply the model to the test set ...\n",
    "import sklearn.metrics\n",
    "print(\"Accuracy score on test set: %.2f%%\" % sklearn.metrics.accuracy_score(y_test, search.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Conclusions:</u>\n",
    "\n",
    "CV is ok for assessing the variance of a **given** model when trained/tested on different sets, but ...\n",
    "\n",
    "When performing **model selection**:\n",
    "\n",
    "- The validation set(s) in the CV can only be used to **select** the best configuration.\n",
    "\n",
    "- You _cannot_ use the validation set to select the model **and** evaluate the performance!\n",
    "\n",
    "- To assess the performance, you need a **test set**.\n",
    "\n",
    "  Or else you are gonna bias the estimation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection and assessment $-$ the right way\n",
    "\n",
    "Let's formulate the problem in the general case of **Model Selection**, i.e. select among a variety of models and report their performance.\n",
    "\n",
    "_NOTE: The line between **hyperparameter tuning** and model **model selection** is in fact very thin, since $-$ as we have seen $-$ a model can be seen as a configuration which might \"switch\" on or off a specific algorithm._\n",
    "\n",
    "<font size=3><u>**Unbiased estimations**</u><font>\n",
    "\n",
    "In general, we would like a learning method for selecting the best model and fitting, which is not biased in its performance estimation:\n",
    "- If we have many, many data $\\rightarrow$ CV + hold-out set\n",
    "\n",
    "- If we have few data, need to cycle through $\\rightarrow$ CV + **Nested Cross Validation (NCV)**!\n",
    "\n",
    "> CV $\\leftarrow$ gives us the **best model**\n",
    "\n",
    "> NCV $\\leftarrow$ gives us **performance assessment** of our CV method\n",
    "\n",
    "<font size=3><u>**How NCV works**</u><font>\n",
    "\n",
    "First of all, let's think of CVT as a **learning method**:\n",
    "\n",
    "- As an **input**, it takes the data\n",
    "- **Inside**, it learns to select the best model\n",
    "- As an **output**, it returns the best model\n",
    "\n",
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/CVT_learning_method.png\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 5. Cross Validation with Tuning as a learning method.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Issue:</u> In CVT, we don't have a test set to independently estimate the selected model performance.\n",
    "\n",
    "So why not add one more **outer** cross-validation which isolates a test set at each split?!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/NCV_k4.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 6. Nested Cross Validation protocol.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, NCV cross-validates the CVT!\n",
    "\n",
    "The **performance estimate** will be $\\rightarrow$ the **average performance over the outer loop**.\n",
    "\n",
    "- - -\n",
    "\n",
    "<font size=3><u>**Important**</u><font>\n",
    "\n",
    "Notice how the model (configuration) selected by each CVT **can be different**!\n",
    " \n",
    "That means that the output distribution of performances is generated by different fitted algorithms!\n",
    "It does _not_ refer to the specific best configuration!\n",
    " \n",
    "In practice, the actual configuration of the final model is not so relevant, what is relevant is that <u>we can fit the input data with <_this much_> accuracy</u>.\n",
    "<br>\n",
    "\n",
    "<details>\n",
    "<summary><b>[Spoiler]</b></summary>\n",
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/Model_Not_Important.jpg\">\n",
    "    </td>\n",
    "</tr></table>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3><u>**Final model**</u><font>\n",
    "\n",
    "    What is the final model? The one with the best score in outer loop?\n",
    "\n",
    "NO $\\rightarrow$ NCV only assesses the **performance of our learning method** (CVT).    \n",
    "\n",
    "If you want the best model, just run **CVT on all the data**.\n",
    "    \n",
    "See discussion [here](https://stats.stackexchange.com/questions/65128/nested-cross-validation-for-model-selection).\n",
    "\n",
    "<font size=3><u>**Useful links**</u><font>\n",
    "\n",
    "[ - ] NCV with [<code>sklearn</code>](https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html)\n",
    "\n",
    "[ - ] A marvellous [introductive guide](https://machinelearningmastery.com/nested-cross-validation-for-machine-learning-with-python/) by J. Brownlee\n",
    "\n",
    "[ - ] Final model: better retrain on the **best** configuration, or on an **ensamble** of the best inner models?\n",
    "See the considerations [here](https://www.analyticsvidhya.com/blog/2021/03/a-step-by-step-guide-to-nested-cross-validation/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try NCV to assess our learning method\n",
    "\n",
    "Two nice methods to implement CV for multpile classifiers can be found [here](https://stackoverflow.com/questions/23045318/grid-search-over-multiple-classifiers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from termcolor import colored, cprint\n",
    "# NCV utilities:\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from pipelinehelper import PipelineHelper\n",
    "from collections import OrderedDict\n",
    "# Scalers:\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "# Classifiers:\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Metrics:\n",
    "import sklearn.metrics\n",
    "# Ignore sklearn warnings (remove when ready!):\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nested CV setup variables --------------------------------------------------\n",
    "# Use a larger value for the outer loop (e.g. 10) than for the inner loop (e.g. 3) -- See:\n",
    "#     https://machinelearningmastery.com/how-to-configure-k-fold-cross-validation\n",
    "n_splits_outer = 5 #10\n",
    "# number of folds in outer CV \n",
    "n_splits_inner = 3\n",
    "# number of folds in inner CV \n",
    "#-----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_CV(X_train, y_train, n_splits_inner, verbose=0):\n",
    "    '''\n",
    "    Inner CV loop, implemented using PipelineHelper: \n",
    "        https://github.com/bmurauer/pipelinehelper\n",
    "        \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train, y_train : np.ndarray, np.array\n",
    "        Data over which to perform the inner CV.\n",
    "    n_splits_inner : int\n",
    "        Number of k-folds for the inner loop.\n",
    "    '''\n",
    "    \n",
    "    '''Define here all possible models that you want to attemp:\n",
    "    \n",
    "        In particular, this pipeline trains, for each CV iteration, one\n",
    "        combination of:\n",
    "       - a scaler (sampled between StandardScaler or MaxAbsScaler)\n",
    "       - a classifier (sampled between LinearSVC or RandomForestClassifier)\n",
    "    '''\n",
    "    \n",
    "    models = Pipeline([\n",
    "        ('scaler', PipelineHelper([\n",
    "            ('std', StandardScaler()),\n",
    "            ('max', MaxAbsScaler()),\n",
    "        ])),\n",
    "        ('classifier', PipelineHelper([\n",
    "            ('svm', LinearSVC()),\n",
    "            ('rf', RandomForestClassifier()),\n",
    "        ])),\n",
    "    ])\n",
    "\n",
    "    '''Define here the parameter you want to sample, for each scaler\n",
    "    and each classifier:\n",
    "    \n",
    "        In particular, this pipeline tries:\n",
    "        - using mean and/or standard deviation to scale the data\n",
    "        - different C parameters for the Support Vector machine Classifier \n",
    "        - different n_estimators for the Random Forsests\n",
    "        \n",
    "        NOTE1: MaxAbsScaler takes no parameters!\n",
    "        NOTE2: You can just through in all the parameters, the PipelineHelper\n",
    "               will take care to attribute them to the correct algorithm\n",
    "    '''\n",
    "    \n",
    "    param_grid = {\n",
    "        'scaler__selected_model': models.named_steps['scaler'].generate({\n",
    "            'std__with_mean': [True, False],\n",
    "            'std__with_std': [True, False],\n",
    "        }),\n",
    "        'classifier__selected_model': models.named_steps['classifier'].generate({\n",
    "            'svm__C': [0.1, 1.0],\n",
    "            'rf__n_estimators': [20, 100],\n",
    "        })\n",
    "    }\n",
    "    \n",
    "    search = GridSearchCV(models, param_grid, scoring='accuracy',\n",
    "                        cv=n_splits_inner, refit=True, verbose=verbose)\n",
    "\n",
    "    result = search.fit(X_train, y_train)\n",
    "    # NOTE: After GridSearch finds the best model, it re-fits it on the whole\n",
    "    #       X_train set and returns it as the best model\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m> Outer iteration 1 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.86 | test = 0.81\n",
      "\tSelected config: {'classifier__selected_model': ('rf', {'n_estimators': 100}), 'scaler__selected_model': ('std', {'with_mean': False, 'with_std': True})}\n",
      "\n",
      "\u001b[31m> Outer iteration 2 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.83 | test = 0.86\n",
      "\tSelected config: {'classifier__selected_model': ('svm', {'C': 0.1}), 'scaler__selected_model': ('std', {'with_mean': True, 'with_std': False})}\n",
      "\n",
      "\u001b[31m> Outer iteration 3 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.79 | test = 0.90\n",
      "\tSelected config: {'classifier__selected_model': ('rf', {'n_estimators': 100}), 'scaler__selected_model': ('std', {'with_mean': True, 'with_std': False})}\n",
      "\n",
      "\u001b[31m> Outer iteration 4 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.86 | test = 0.79\n",
      "\tSelected config: {'classifier__selected_model': ('svm', {'C': 0.1}), 'scaler__selected_model': ('std', {'with_mean': True, 'with_std': True})}\n",
      "\n",
      "\u001b[31m> Outer iteration 5 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.83 | test = 0.76\n",
      "\tSelected config: {'classifier__selected_model': ('svm', {'C': 0.1}), 'scaler__selected_model': ('std', {'with_mean': True, 'with_std': True})}\n",
      "\n",
      "\n",
      "Mean test score: 0.824 (+/-0.051)\n",
      "\n",
      "CPU times: user 10.4 s, sys: 49.6 ms, total: 10.4 s\n",
      "Wall time: 10.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def run_NCV(X_train, y_train, n_splits_outer, n_splits_inner, inner_CV=inner_CV):\n",
    "\n",
    "    # Configuring the outer CV procedure:\n",
    "    cv_outer = KFold(n_splits=n_splits_outer, shuffle=True, random_state=42)\n",
    "\n",
    "    outer_scores = OrderedDict()\n",
    "    # dictionary of scores for the best models found at each outer iteration <indexed by outer CV iteration>\n",
    "    best_inner_models = []\n",
    "    # list of trained best models found at each inner iteration <indexed by outer CV iteration>\n",
    "\n",
    "    for i, (train_ix, test_ix) in enumerate(cv_outer.split(X_train)):\n",
    "    # outer CV loop\n",
    "    # NOTE: We will only use the training set for the NCV, and further split it.\n",
    "    #       We want to keep the hold-out set for the final check!\n",
    "\n",
    "        cprint('> Outer iteration %s [of %s]' % (i+1, n_splits_outer), 'red')\n",
    "\n",
    "        # Splitting outer CV data in train and test:\n",
    "        X_outer_train, X_outer_test = X_train[train_ix, :], X_train[test_ix, :]\n",
    "        y_outer_train, y_outer_test = y_train[train_ix]   , y_train[test_ix]\n",
    "\n",
    "        # > Executing the search (i.e., the inner CV loop):\n",
    "        result = inner_CV(X_outer_train, y_outer_train, n_splits_inner)\n",
    "        # NOTE: Inside the inner CV, X_outer_train will be further split in the\n",
    "        #       inner train and validation sets by GridSearchCV\n",
    "\n",
    "        # Getting the best performing model from the inner iteration:\n",
    "        best_inner_model = result.best_estimator_\n",
    "\n",
    "        # > Evaluating model on the test fold\n",
    "\n",
    "        # Predicting labels on the outer test fold:\n",
    "        yhat_outer_test = best_inner_model.predict(X_outer_test)\n",
    "\n",
    "        # Scoring the model on test fold:\n",
    "        score = sklearn.metrics.accuracy_score(y_outer_test, yhat_outer_test)\n",
    "\n",
    "        best_inner_models.append(best_inner_model)\n",
    "\n",
    "        # Storing score result for current [outer CV] fold:\n",
    "        outer_scores[str(i)] = OrderedDict({  \n",
    "            'score': score,\n",
    "            'cfg': result.best_params_\n",
    "        })\n",
    "\n",
    "        print('\\tScore: valid = %.2f | test = %.2f' % (np.abs(result.best_score_), score))\n",
    "        print('\\tSelected config: %s' % result.best_params_, end='\\n\\n')\n",
    "\n",
    "    # Converting <outer_models> to a dataframe, for better visualization:\n",
    "    df_score = pd.DataFrame([outer_score['score'] for key, outer_score in outer_scores.items()], columns=['score'])\n",
    "    df_cfg   = pd.DataFrame([outer_score['cfg'] for key, outer_score in outer_scores.items()])\n",
    "    df_outer_scores = pd.concat([df_score, df_cfg], axis=1)\n",
    "\n",
    "    # Summarizing the estimated performance of the model:\n",
    "    print()\n",
    "    print('Mean test score: %.3f (+/-%.3f)\\n' %\n",
    "          (np.mean(df_outer_scores['score']), np.std(df_outer_scores['score'])))\n",
    "    \n",
    "    return df_outer_scores, best_inner_models\n",
    "\n",
    "df_outer_scores, best_inner_models = \\\n",
    "    run_NCV(X_train, y_train, n_splits_outer, n_splits_inner, inner_CV=inner_CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer CV configurations:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>classifier__selected_model</th>\n",
       "      <th>scaler__selected_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.809524</td>\n",
       "      <td>(rf, {'n_estimators': 100})</td>\n",
       "      <td>(std, {'with_mean': False, 'with_std': True})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>(svm, {'C': 0.1})</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': False})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.904762</td>\n",
       "      <td>(rf, {'n_estimators': 100})</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': False})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.785714</td>\n",
       "      <td>(svm, {'C': 0.1})</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': True})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.761905</td>\n",
       "      <td>(svm, {'C': 0.1})</td>\n",
       "      <td>(std, {'with_mean': True, 'with_std': True})</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score   classifier__selected_model  \\\n",
       "0  0.809524  (rf, {'n_estimators': 100})   \n",
       "1  0.857143            (svm, {'C': 0.1})   \n",
       "2  0.904762  (rf, {'n_estimators': 100})   \n",
       "3  0.785714            (svm, {'C': 0.1})   \n",
       "4  0.761905            (svm, {'C': 0.1})   \n",
       "\n",
       "                          scaler__selected_model  \n",
       "0  (std, {'with_mean': False, 'with_std': True})  \n",
       "1  (std, {'with_mean': True, 'with_std': False})  \n",
       "2  (std, {'with_mean': True, 'with_std': False})  \n",
       "3   (std, {'with_mean': True, 'with_std': True})  \n",
       "4   (std, {'with_mean': True, 'with_std': True})  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Outer CV configurations:')\n",
    "display(df_outer_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Final remarks:</u>\n",
    "\n",
    "A comparison of the expectiation values for repeated experiments with CV and NCV is provided by this <code>sklearn</code> [notebook](https://inria.github.io/scikit-learn-mooc/python_scripts/cross_validation_nested.html) (remember Equation 1?).\n",
    "\n",
    "Notice though that the code in that notebook does not allow to easily generalize to combination of algorithms, e.g. scaler $+$ classifier, or even to multiple classifiers.  For that purpose, use the <code>inner_CV</code> function above. \n",
    "\n",
    "<table><tr>\n",
    "    <td width=400>\n",
    "        <img src=\"images/NCV_vs_CV.png\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 7. Comparison of accuracy estimates from repeated Nested Cross Validation and Cross Validation.\n",
    "            <br>\n",
    "            (From <a href=\"https://inria.github.io/scikit-learn-mooc/python_scripts/cross_validation_nested.html\">here</a>)\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXERCISE 1: Create your own NCV\n",
    "\n",
    "You must:\n",
    "\n",
    "- use <code>RandomizedSearchCV</code> (documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html))\n",
    "\n",
    "  _instead of the <code>GridSearchCV</code> we used before.\n",
    "  You can assume a uniform distribution for all the parameters, to start with._<br><br>\n",
    "  \n",
    "  - to sample integers: [<code>scipy.stats.randint</code>](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.randint.html)\n",
    "  - to sample floats: [<code>scipy.stats.uniform</code>](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.uniform.html)\n",
    "  - or pass a list of possible values for categorical data\n",
    "  <br><br>\n",
    "  \n",
    "- use any collection of <code>sklearn</code> classifiers, and associated hyperparameters, you like (a complete list [here](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html))\n",
    "\n",
    "  _but watch your clock!  The more classifiers you put into the NCV, the more time it will take!_<br><br>\n",
    "  \n",
    "- [Optional] try with different numbers of inner and outer folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from termcolor import colored, cprint\n",
    "# NCV utilities:\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from pipelinehelper import PipelineHelper\n",
    "from collections import OrderedDict\n",
    "# Scalers:\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "# Classifiers:\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "# Metrics:\n",
    "import sklearn.metrics\n",
    "# Ignore sklearn warnings (remove when ready!):\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nested CV setup variables --------------------------------------------------\n",
    "# Use a larger value for the outer loop (e.g. 10) than for the inner loop (e.g. 3) -- See:\n",
    "#     https://machinelearningmastery.com/how-to-configure-k-fold-cross-validation\n",
    "n_splits_outer = 5\n",
    "# number of folds in outer CV \n",
    "n_splits_inner = 3\n",
    "# number of folds in inner CV \n",
    "#-----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform\n",
    "from scipy.stats import randint\n",
    "\n",
    "def my_inner_CV(X_train, y_train, n_splits_inner, verbose=0):\n",
    "    \n",
    "    models = Pipeline([\n",
    "        ('scaler', PipelineHelper([\n",
    "            ('max', MaxAbsScaler()),\n",
    "            ('qtt', QuantileTransformer(random_state=0, n_quantiles=10)),\n",
    "        ])),\n",
    "        ('classifier', PipelineHelper([\n",
    "            ('gpc', GaussianProcessClassifier()),\n",
    "            ('knn', KNeighborsClassifier()),\n",
    "        ])),\n",
    "    ])\n",
    "    \n",
    "    param_grid = {\n",
    "        'scaler__selected_model': models.named_steps['scaler'].generate({\n",
    "            'qtt__output_distribution': ['normal', 'uniform'],\n",
    "        }),\n",
    "        'classifier__selected_model': models.named_steps['classifier'].generate({\n",
    "            'gpc__kernel': [RBF(1.0), RBF(5.0)],\n",
    "            'knn__n_neighbors': randint(3, 20).rvs(size=4),\n",
    "        })\n",
    "    }\n",
    "    \n",
    "    search = RandomizedSearchCV(models, param_grid, scoring='accuracy',\n",
    "                        cv=n_splits_inner, refit=True, verbose=verbose)\n",
    "\n",
    "    result = search.fit(X_train, y_train)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m> Outer iteration 1 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.86 | test = 0.83\n",
      "\tSelected config: {'scaler__selected_model': ('qtt', {'output_distribution': 'uniform'}), 'classifier__selected_model': ('gpc', {'kernel': RBF(length_scale=5)})}\n",
      "\n",
      "\u001b[31m> Outer iteration 2 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.83 | test = 0.88\n",
      "\tSelected config: {'scaler__selected_model': ('qtt', {'output_distribution': 'normal'}), 'classifier__selected_model': ('gpc', {'kernel': RBF(length_scale=1)})}\n",
      "\n",
      "\u001b[31m> Outer iteration 3 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.80 | test = 0.95\n",
      "\tSelected config: {'scaler__selected_model': ('qtt', {'output_distribution': 'uniform'}), 'classifier__selected_model': ('knn', {'n_neighbors': 8})}\n",
      "\n",
      "\u001b[31m> Outer iteration 4 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.85 | test = 0.79\n",
      "\tSelected config: {'scaler__selected_model': ('qtt', {'output_distribution': 'uniform'}), 'classifier__selected_model': ('knn', {'n_neighbors': 10})}\n",
      "\n",
      "\u001b[31m> Outer iteration 5 [of 5]\u001b[0m\n",
      "\tScore: valid = 0.85 | test = 0.81\n",
      "\tSelected config: {'scaler__selected_model': ('qtt', {'output_distribution': 'uniform'}), 'classifier__selected_model': ('knn', {'n_neighbors': 14})}\n",
      "\n",
      "\n",
      "Mean test score: 0.852 (+/-0.059)\n",
      "\n",
      "CPU times: user 19.9 s, sys: 16.3 s, total: 36.2 s\n",
      "Wall time: 4.84 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_outer_scores, best_inner_models = \\\n",
    "    run_NCV(X_train, y_train, n_splits_outer, n_splits_inner, inner_CV=my_inner_CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer CV configurations:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>scaler__selected_model</th>\n",
       "      <th>classifier__selected_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>(qtt, {'output_distribution': 'uniform'})</td>\n",
       "      <td>(gpc, {'kernel': RBF(length_scale=5)})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.880952</td>\n",
       "      <td>(qtt, {'output_distribution': 'normal'})</td>\n",
       "      <td>(gpc, {'kernel': RBF(length_scale=1)})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.952381</td>\n",
       "      <td>(qtt, {'output_distribution': 'uniform'})</td>\n",
       "      <td>(knn, {'n_neighbors': 8})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.785714</td>\n",
       "      <td>(qtt, {'output_distribution': 'uniform'})</td>\n",
       "      <td>(knn, {'n_neighbors': 10})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.809524</td>\n",
       "      <td>(qtt, {'output_distribution': 'uniform'})</td>\n",
       "      <td>(knn, {'n_neighbors': 14})</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score                     scaler__selected_model  \\\n",
       "0  0.833333  (qtt, {'output_distribution': 'uniform'})   \n",
       "1  0.880952   (qtt, {'output_distribution': 'normal'})   \n",
       "2  0.952381  (qtt, {'output_distribution': 'uniform'})   \n",
       "3  0.785714  (qtt, {'output_distribution': 'uniform'})   \n",
       "4  0.809524  (qtt, {'output_distribution': 'uniform'})   \n",
       "\n",
       "               classifier__selected_model  \n",
       "0  (gpc, {'kernel': RBF(length_scale=5)})  \n",
       "1  (gpc, {'kernel': RBF(length_scale=1)})  \n",
       "2               (knn, {'n_neighbors': 8})  \n",
       "3              (knn, {'n_neighbors': 10})  \n",
       "4              (knn, {'n_neighbors': 14})  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Outer CV configurations:')\n",
    "display(df_outer_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE 1.2: Find the final model via an additional CVT\n",
    "\n",
    "And report the score on the hold-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "CPU times: user 4.67 s, sys: 3.77 s, total: 8.44 s\n",
      "Wall time: 1.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "search = my_inner_CV(X_train, y_train, n_splits_inner, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration:\n",
      "{'scaler__selected_model': ('qtt', {'output_distribution': 'uniform'}), 'classifier__selected_model': ('knn', {'n_neighbors': 10})}\n",
      "Accuracy score on test set: 0.80%\n"
     ]
    }
   ],
   "source": [
    "print(\"Best configuration:\")\n",
    "print(search.best_params_)\n",
    "\n",
    "# And in fact, when we apply the model to the test set ...\n",
    "import sklearn.metrics\n",
    "print(\"Accuracy score on test set: %.2f%%\" % sklearn.metrics.accuracy_score(y_test, search.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to pick the hyperparameters/algorithms to explore?\n",
    "\n",
    "The possible varaints one can try when exploring models are potentially very large.<br>\n",
    "We cannot afford to spend infinite time fitting!\n",
    "\n",
    "Solutions include:\n",
    " - consider previous knowledge of models performance in the learning method (**meta features**)\n",
    " - **early dropping** of poorly performing models (_not to fit them at every iteration_)\n",
    " - address the whole issue as an **optimization problem**\n",
    " \n",
    " There are plenty of optimization algorithms, and we leave it up to you to study them.\n",
    " \n",
    " > A safe all-round bet might be the successful **Bayesian Optimization**: [here](https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f) you can find a good introduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td width=640>\n",
    "        <img src=\"images/Know_More.jpg\">\n",
    "        <center>\n",
    "            <br>\n",
    "            Figure 8.  Check Bayesian Optimization before the insects take over.\n",
    "            <br>\n",
    "        </center>\n",
    "    </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto ML\n",
    "\n",
    "> **Auto ML**: Automated hyperparameter search, and model selection, with techniques\n",
    "    allowing to select which algorithms to try out (_i.e., avoiding extensive search_).\n",
    "\n",
    "There are many services providing auto ML out there $-$ here we will look at the \n",
    "<code>[auto-sklearn](https://automl.github.io/auto-sklearn/master/)</code>\n",
    "implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/software/anaconda3/envs/autoML/lib/python3.9/site-packages/autosklearn/metalearning/metalearning/meta_base.py:68: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.metafeatures = self.metafeatures.append(metafeatures)\n",
      "/data/software/anaconda3/envs/autoML/lib/python3.9/site-packages/autosklearn/metalearning/metalearning/meta_base.py:72: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.algorithm_runs[metric].append(runs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51.9 s, sys: 1.06 s, total: 53 s\n",
      "Wall time: 1min 58s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoSklearnClassifier(ensemble_size=1, per_run_time_limit=12,\n",
       "                      time_left_for_this_task=120)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import autosklearn.classification\n",
    "\n",
    "# Defining the automl learning method:\n",
    "automl = autosklearn.classification.AutoSklearnClassifier(\n",
    "                                ensemble_size=1, time_left_for_this_task=120)\n",
    "# Fitting (this will take at most <time_left_for_this_task> seconds):\n",
    "automl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto-sklearn results:\n",
      "  Dataset name: 62300dd8-02f9-11ed-9450-1002b5312d0b\n",
      "  Metric: accuracy\n",
      "  Best validation score: 0.928571\n",
      "  Number of target algorithm runs: 53\n",
      "  Number of successful target algorithm runs: 53\n",
      "  Number of crashed target algorithm runs: 0\n",
      "  Number of target algorithms that exceeded the time limit: 0\n",
      "  Number of target algorithms that exceeded the memory limit: 0\n",
      "\n",
      "Accuracy score on test set: 0.83%\n"
     ]
    }
   ],
   "source": [
    "print(automl.sprint_statistics())\n",
    "\n",
    "# Predicting labels of test set:\n",
    "import sklearn.metrics\n",
    "\n",
    "yhat_test = automl.predict(X_test)\n",
    "\n",
    "print(\"Accuracy score on test set: %.2f%%\" % sklearn.metrics.accuracy_score(y_test, yhat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the best model details\n",
    "\n",
    "Let's have a look into the model which has been selected out of all the models that the <code>auto-sklearn</code> has tried out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Selected model ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{43: {'model_id': 43,\n",
       "  'rank': 1,\n",
       "  'cost': 0.0714285714285714,\n",
       "  'ensemble_weight': 1.0,\n",
       "  'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice at 0x7f05ed106be0>,\n",
       "  'balancing': Balancing(random_state=1, strategy='weighting'),\n",
       "  'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice at 0x7f05a5db2790>,\n",
       "  'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice at 0x7f05a5dd67f0>,\n",
       "  'sklearn_classifier': MLPClassifier(alpha=8.045852733635899e-06, beta_1=0.999, beta_2=0.9,\n",
       "                early_stopping=True, hidden_layer_sizes=(112, 112),\n",
       "                learning_rate_init=0.00020139694272470796, max_iter=32,\n",
       "                n_iter_no_change=32, random_state=1, verbose=0, warm_start=True)}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "print('=== Selected model ===')\n",
    "display(automl.show_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Details of the \"data_preprocessing\" ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'random_state': 1,\n",
       " 'choice': FeatTypeSplit(column_transformer=ColumnTransformer(sparse_threshold=0.0,\n",
       "                                                    transformers=[('numerical_transformer',\n",
       "                                                                   NumericalPreprocessingPipeline(config=Configuration:\n",
       "   imputation:strategy, Value: 'median'\n",
       "   rescaling:__choice__, Value: 'standardize'\n",
       " , dataset_properties={'signed': False, 'sparse': False}, exclude={}, include={}, init_params={}, steps=[('imputation', Num...\n",
       "                       'categorical_transformer:category_coalescence:__choice__': 'no_coalescense',\n",
       "                       'numerical_transformer:imputation:strategy': 'median',\n",
       "                       'numerical_transformer:rescaling:__choice__': 'standardize'},\n",
       "               feat_type={0: 'numerical', 1: 'numerical', 2: 'numerical',\n",
       "                          3: 'numerical', 4: 'numerical', 5: 'numerical',\n",
       "                          6: 'numerical', 7: 'numerical', 8: 'numerical',\n",
       "                          9: 'numerical'},\n",
       "               init_params={}),\n",
       " 'fitted_': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Details of the \"balancing\" ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'strategy': 'weighting', 'random_state': 1, 'fitted_': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Details of the \"feature_preprocessor\" ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'random_state': 1,\n",
       " 'choice': PolynomialFeatures(degree=2, include_bias=True, interaction_only=False,\n",
       "                    random_state=1),\n",
       " 'new_params': {'degree': 2,\n",
       "  'include_bias': 'True',\n",
       "  'interaction_only': 'False',\n",
       "  'random_state': 1},\n",
       " 'fitted_': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for model_id, model in automl.show_models().items():\n",
    "    print('--- Details of the \"data_preprocessing\" ---')\n",
    "    display(model['data_preprocessor'].__dict__)\n",
    "    \n",
    "    print('--- Details of the \"balancing\" ---')\n",
    "    display(model['balancing'].__dict__)\n",
    "    \n",
    "    print('--- Details of the \"feature_preprocessor\" ---')\n",
    "    display(model['feature_preprocessor'].__dict__)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final remarks on autoML\n",
    "\n",
    "You can use <code>auto-sklearn</code> almost blindly $-$ but $-$ to understand the results ...\n",
    "\n",
    "$\\rightarrow$ Read the docs!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
